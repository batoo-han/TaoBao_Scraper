# Архитектура

## Компоненты

- **`main.py`** — точка входа. Инициализирует `aiogram.Bot`, `Dispatcher`, обработчик ошибок и запускает long polling.
- **`src/bot/handlers.py`** — высокоуровневые обработчики Telegram. Принимают ссылки, валидируют их и вызывают `Scraper`.
- **`src/core/scraper.py`** — центральный оркестратор. Определяет платформу, получает данные через `tmapi.py`/`PinduoduoWebScraper`, нормализует их, формирует компактный датасет и обращается к LLM.
- **`src/api/llm_provider.py`** — фабрика провайдеров (YandexGPT или OpenAI). Читает `DEFAULT_LLM`, кэширует выбранный клиент и единую промпт-логику.
- **`src/api/yandex_gpt.py`** — клиент YandexGPT. Использует общий промпт и настройки Yandex Cloud.
- **`src/api/openai_client.py`** — клиент OpenAI. Работает через `AsyncOpenAI`, поддерживает модели `gpt-4o-mini`, `gpt-4.1-mini`, `gpt-4o`, `o4-mini`.
- **`src/api/prompts.py`** — единый шаблон промпта для всех LLM, чтобы поведение оставалось идентичным.
- **`src/api/tmapi.py`** — клиент для `tmapi.top` с автоматическим выбором площадки.
- **`src/api/exchange_rate.py`** — получение курса CNY→RUB через `exchangerate-api.com` и кэширование результата.
- **`src/api/yandex_translate.py`** — вспомогательный сервис перевода описаний Pinduoduo перед генерацией поста.
- **`src/core/config.py`** — загрузка и валидация конфигурации (включая `DEFAULT_LLM`, `OPENAI_*`, `YANDEX_*`).
- **`.env`** — единый источник секретов (Bot Token, TMAPI, LLM ключи, переключатели).
- **`requirements.txt`** — полный список зависимостей, включая `openai`.
- **`Dockerfile` / `docker-compose.yml`** — контейнеризация и развёртывание.

## Поток данных

1. Пользователь отправляет ссылку на товар в Telegram.
2. `handlers.py` вызывает `Scraper` и передаёт ссылку, пользовательские параметры и контекст.
3. `Scraper` определяет площадку (`Taobao/Tmall` через `tmapi`, `Pinduoduo` через веб-скрейпер) и собирает данные.
4. Опционально запрашивается `exchange_rate.py`, если включена конвертация валют.
5. Данные нормализуются и передаются в `llm_provider`, который на основании `DEFAULT_LLM` выбирает `YandexGPT` или `OpenAI`.
6. Выбранный LLM получает общий промпт и возвращает строго структурированный JSON.
7. `Scraper` пост-обрабатывает ответ (валидация характеристик, генерация HTML-поста) и формирует список изображений.
8. `handlers.py` отправляет медиагруппу и готовый пост пользователю, а ошибки централизованно логируются и ротируются.