## Оптимизация затрат на OpenAI (токены и время)

Документ описывает изменения, направленные на сокращение числа токенов и стоимости запросов к моделям OpenAI.
Все изменения применяются **только к провайдеру OpenAI** и не затрагивают YandexGPT/ProxyAPI (если явно не указано).

### Цели

- **Снизить входные токены**: уменьшить объём JSON, отправляемого в модель, и убрать лишнее форматирование.
- **Сохранить качество**: сухое, точное описание товара без «воды», соблюдение правил шаблона.
- **Сохранить обратную совместимость**: возможность быстро переключаться между вариантами поведения через `.env`.

---

## 1) Стратегия OpenAI: single_pass vs legacy

Настройка: `OPENAI_STRATEGY`

- **`single_pass`** (по умолчанию): в OpenAI отправляются только нужные поля TMAPI (в урезанном виде), модель сразу переводит и формирует итоговый JSON.
- **`legacy`**: старый сценарий (предварительный перевод отдельных полей + общий промпт).

---

## 1.1) Совместимость моделей (gpt-5* и Responses API)

В проекте для OpenAI используется **Chat Completions API** (Responses API отключён из-за скорости).
Модели семейства **gpt-5*** могут работать некорректно в этом режиме и иногда возвращать пустой `content`.

Настройка: `OPENAI_FALLBACK_CHAT_MODEL`

- Если `OPENAI_MODEL` начинается с `gpt-5`, клиент автоматически переключится на `OPENAI_FALLBACK_CHAT_MODEL` (по умолчанию `gpt-4o-mini`).

## 2) Сокращение данных (главный источник экономии входных токенов)

В режиме `single_pass` данные ужимаются в `src/core/scraper.py` в методе `_prepare_openai_single_pass_payload`.

### Что отправляем в OpenAI

- **`title`**
- **`price` / `price_info`** (в `price_info` оставляем только ключевые цены)
- **`product_props`** (с фильтрацией «пол/возраст» и обрезкой слишком длинных значений)
- **`sku_props`** (только `prop_name` и `values[].name`, без `imageUrl`, `vid`)
- **`skus`** (только `props_names` и `sale_price`, без `skuid`, `stock`, `props_ids` и т.п.)

### Лимиты (регулируются через `.env`)

- `OPENAI_SINGLE_PASS_MAX_SKUS` (по умолчанию `120`)
- `OPENAI_SINGLE_PASS_MAX_SKU_VALUES` (по умолчанию `60`)
- `OPENAI_SINGLE_PASS_MAX_PROP_VALUE_LEN` (по умолчанию `220`)

---

## 3) Уменьшение «мусорных» токенов: компактный JSON

Чтобы не платить за пробелы/переносы строк, для OpenAI используется компактная сериализация JSON:

- `json.dumps(..., separators=(",", ":"))`

Это применяется в OpenAI-клиенте (и аналогично в остальных клиентах для экономии, но OpenAI‑контур контролируется отдельно).

---

## 4) Оптимизация промпта OpenAI (без роутера)

Настройка: `OPENAI_PROMPT_VARIANT`

- **`compact_v1`** (по умолчанию): компактный OpenAI‑промпт без длинных примеров и повторов.
- **`compact_v2`**: компактный OpenAI‑промпт со строгими анти‑галлюцинационными правилами (рекомендуется).
- **`shared`**: использовать общий промпт `POST_GENERATION_PROMPT` (длинный).

Промпт выбирается только в `src/api/openai_client.py` и **не влияет** на YandexGPT/ProxyAPI.

---

## 5) Ограничение выходных токенов (ключ к экономии, когда completion дорогой)

Настройка: `OPENAI_MAX_OUTPUT_TOKENS`

- Управляет максимально допустимым числом **выходных** токенов при генерации JSON-поста OpenAI.
- Если стоимость доминирует по **исходящим токенам**, уменьшение этого лимита даёт заметную экономию.
- Слишком низкое значение может приводить к обрезанному JSON — тогда лимит нужно поднять.

## Рекомендуемый порядок тестирования

1) Зафиксировать базовую метрику токенов/стоимости для 1–3 ссылок Taobao и 1–3 ссылок 1688.
2) Включить `OPENAI_STRATEGY=single_pass` и проверить, что качество не просело.
3) Подкрутить лимиты `OPENAI_SINGLE_PASS_*` и проверить влияние на входные токены.
4) Переключить `OPENAI_PROMPT_VARIANT=compact_v2` и повторно сравнить качество/стоимость.
5) Подобрать `OPENAI_MAX_OUTPUT_TOKENS` под нужный баланс качества/цены (обычно 1200–2400).


