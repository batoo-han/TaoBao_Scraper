## Оптимизация затрат на OpenAI (токены и время)

Документ описывает изменения, направленные на сокращение числа токенов и стоимости запросов к моделям OpenAI.
Все изменения применяются **только к провайдеру OpenAI** и не затрагивают YandexGPT/ProxyAPI (если явно не указано).

### Цели

- **Снизить входные токены**: уменьшить объём JSON, отправляемого в модель, и убрать лишнее форматирование.
- **Сохранить качество**: сухое, точное описание товара без «воды», соблюдение правил шаблона.
- **Сохранить обратную совместимость**: возможность быстро переключаться между вариантами поведения через `.env`.

---

## 1) Стратегия OpenAI: single_pass vs legacy

Настройка: `OPENAI_STRATEGY`

- **`single_pass`** (по умолчанию): в OpenAI отправляются только нужные поля TMAPI (в урезанном виде), модель сразу переводит и формирует итоговый JSON.
- **`legacy`**: старый сценарий (предварительный перевод отдельных полей + общий промпт).

---

## 1.1) Совместимость моделей (gpt-5* и Responses API)

В проекте для OpenAI используется **Chat Completions API** (Responses API отключён из-за скорости).
Модели семейства **gpt-5*** могут работать некорректно в этом режиме и иногда возвращать пустой `content`.

Настройка: `OPENAI_FALLBACK_CHAT_MODEL`

- Если `OPENAI_MODEL` начинается с `gpt-5`, клиент автоматически переключится на `OPENAI_FALLBACK_CHAT_MODEL` (по умолчанию `gpt-4o-mini`).

## 2) Сокращение данных (главный источник экономии входных токенов)

В режиме `single_pass` данные ужимаются в `src/core/scraper.py` в методе `_prepare_openai_single_pass_payload`.

### Что отправляем в OpenAI

- **`title`**
- **`price` / `price_info`** (в `price_info` оставляем только ключевые цены)
- **`product_props`** (с фильтрацией «пол/возраст» и обрезкой слишком длинных значений)
- **`sku_props`** (только `prop_name` и `values[].name`, без `imageUrl`, `vid`)
- **`skus`** (только `props_names` и `sale_price`, без `skuid`, `stock`, `props_ids` и т.п.)

### Лимиты (регулируются через `.env`)

- `OPENAI_SINGLE_PASS_MAX_SKUS` (по умолчанию `120`)
- `OPENAI_SINGLE_PASS_MAX_SKU_VALUES` (по умолчанию `60`)
- `OPENAI_SINGLE_PASS_MAX_PROP_VALUE_LEN` (по умолчанию `220`)

---

## 3) Уменьшение «мусорных» токенов: компактный JSON

Чтобы не платить за пробелы/переносы строк, для OpenAI используется компактная сериализация JSON:

- `json.dumps(..., separators=(",", ":"))`

Это применяется в OpenAI-клиенте (и аналогично в остальных клиентах для экономии, но OpenAI‑контур контролируется отдельно).

---

## 4) Оптимизация промпта OpenAI (без роутера)

Настройка: `OPENAI_PROMPT_VARIANT`

- **`compact_v3`** (рекомендуется): улучшенная версия compact_v2 с жёсткими правилами против китайских иероглифов, улучшенной стилистикой и филологией, а также паттернами для стабильного формирования поста.
- **`compact_v2`**: компактный OpenAI‑промпт со строгими анти‑галлюцинационными правилами.
- **`compact_v1`**: компактный OpenAI‑промпт без длинных примеров и повторов.
- **`shared`**: использовать общий промпт `POST_GENERATION_PROMPT` (длинный).

Промпт выбирается только в `src/api/openai_client.py` и **не влияет** на YandexGPT/ProxyAPI.

### Особенности compact_v3:
- **Жёсткая борьба с китайскими иероглифами**: явная таблица переводов цветов (孔雀绿 → "павлиний зелёный", 黑色 → "чёрный" и т.п.), строгие правила перевода всех китайских текстов.
- **Улучшенная стилистика и филология**: правила про правильное использование числительных ("набор из трёх трусов" вместо "три труса"), согласование по роду/падежу, форматирование размеров ("18 × 12 см" вместо "18.12, см").
- **Паттерны и примеры**: добавлены конкретные примеры правильного и неправильного формирования поста для стабильности.

---

## 5) Ограничение выходных токенов (ключ к экономии, когда completion дорогой)

Настройка: `OPENAI_MAX_OUTPUT_TOKENS`

- Управляет максимально допустимым числом **выходных** токенов при генерации JSON-поста OpenAI.
- Если стоимость доминирует по **исходящим токенам**, уменьшение этого лимита даёт заметную экономию.
- Слишком низкое значение может приводить к обрезанному JSON — тогда лимит нужно поднять.

---

## 6) Постобработка готового поста (отдельный шаг)

Новая опция: `ENABLE_POSTPROCESSING` + `OPENAI_POSTPROCESS_MODEL`

- включает **второй, короткий LLM‑проход** уже по готовому тексту поста;
- используется для:
  - исправления числительных и падежей («три труса» → «три пары трусов» и т.п.),
  - нормализации размеров (`18, 12, см` → `18 × 12 см`),
  - добивания недопереведённых фрагментов (`孔雀绿` → «павлиний зелёный»),
  - лёгкой стилистической полировки без изменения структуры блоков.

Особенности:

- реализовано в `src/api/openai_client.py` методом `postprocess_post_text`;
- используется отдельный клиент через `get_postprocess_client()` (см. `src/api/llm_provider.py`);
- модель постобработки задаётся через `OPENAI_POSTPROCESS_MODEL`
  (рекомендуется компактная модель вроде `gpt-4o-mini`);
- статистика токенов и стоимость постобработки считаются **отдельно** (`TokensUsage`)
  и добавляются к общей статистике запроса в `src/core/scraper.py`.

---

## 7) Генерация хэштегов (отдельный шаг)

Новая опция: `ENABLE_HASHTAGS` + `HASHTAGS_PROVIDER` + `HASHTAGS_MODEL`

- включает **отдельный LLM‑проход** для генерации хэштегов на основе готового поста;
- хэштеги генерируются **после** создания поста, но **до** постобработки;
- используется для создания релевантных хэштегов, отражающих суть товара.

Особенности:

- реализовано в `src/api/openai_client.py`, `src/api/yandex_gpt.py`, `src/api/proxyapi_client.py` методом `generate_hashtags`;
- используется отдельный клиент через `get_hashtags_client()` (см. `src/api/llm_provider.py`);
- провайдер задаётся через `HASHTAGS_PROVIDER` (yandex/openai/proxyapi), если пусто - используется `DEFAULT_LLM`;
- модель задаётся через `HASHTAGS_MODEL`, если пусто - используется модель провайдера по умолчанию;
- статистика токенов и стоимость генерации хэштегов считаются **отдельно** (`TokensUsage`)
  и добавляются к общей статистике запроса в `src/core/scraper.py`;
- поддерживает все провайдеры: YandexGPT, OpenAI, ProxyAPI.

Если постобработка отключена (`ENABLE_POSTPROCESSING=False`) или клиент не может
инициализироваться (нет ключа и т.п.) — основной пайплайн не меняется.

---

## Рекомендуемый порядок тестирования

1) Зафиксировать базовую метрику токенов/стоимости для 1–3 ссылок Taobao и 1–3 ссылок 1688.
2) Включить `OPENAI_STRATEGY=single_pass` и проверить, что качество не просело.
3) Подкрутить лимиты `OPENAI_SINGLE_PASS_*` и проверить влияние на входные токены.
4) Переключить `OPENAI_PROMPT_VARIANT=compact_v2` и повторно сравнить качество/стоимость.
5) Подобрать `OPENAI_MAX_OUTPUT_TOKENS` под нужный баланс качества/цены (обычно 1200–2400).
6) Включить `ENABLE_POSTPROCESSING` + компактную модель в `OPENAI_POSTPROCESS_MODEL`
   и оценить дополнительное качество (особенно на числительных/размерах) и вклад в стоимость.


