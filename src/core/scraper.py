import inspect
import json
import logging
import re
from collections import Counter, OrderedDict, defaultdict

from src.api.tmapi import TmapiClient
from src.api.llm_provider import get_llm_client, get_translation_client
from src.api.exchange_rate import ExchangeRateClient
from src.api.proxyapi_client import ProxyAPIClient
from src.core.config import settings
from src.utils.url_parser import URLParser, Platform
from src.scrapers.pinduoduo_web import PinduoduoWebScraper

logger = logging.getLogger(__name__)

class Scraper:
    """
    –ö–ª–∞—Å—Å-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —Å–±–æ—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–µ, –µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–∞.
    """
    
    COLOR_KEYWORDS = {
        "–±–µ–ª—ã–π", "–±–µ–ª–∞—è", "–±–µ–ª—ã–µ", "—á–µ—Ä–Ω—ã–π", "—á–µ—Ä–Ω–∞—è", "—á–µ—Ä–Ω—ã–µ", "—á—ë—Ä–Ω—ã–π", "—á—ë—Ä–Ω–∞—è", "—á—ë—Ä–Ω—ã–µ",
        "–∫—Ä–∞—Å–Ω—ã–π", "–∫—Ä–∞—Å–Ω–∞—è", "–∫—Ä–∞—Å–Ω—ã–µ", "—Ä–æ–∑–æ–≤—ã–π", "—Ä–æ–∑–æ–≤–∞—è", "—Ä–æ–∑–æ–≤—ã–µ",
        "—Å–∏–Ω–∏–π", "—Å–∏–Ω—è—è", "—Å–∏–Ω–∏–µ", "–≥–æ–ª—É–±–æ–π", "–≥–æ–ª—É–±–∞—è",
        "–∑–µ–ª—ë–Ω—ã–π", "–∑–µ–ª—ë–Ω–∞—è", "–∑–µ–ª—ë–Ω—ã–µ", "–∑–µ–ª–µ–Ω—ã–π", "–∑–µ–ª–µ–Ω–∞—è", "–∑–µ–ª–µ–Ω—ã–µ",
        "–∂—ë–ª—Ç—ã–π", "–∂—ë–ª—Ç–∞—è", "–∂—ë–ª—Ç—ã–µ", "–∂–µ–ª—Ç—ã–π", "–∂–µ–ª—Ç–∞—è", "–∂–µ–ª—Ç—ã–µ",
        "—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π", "—Ñ–∏–æ–ª–µ—Ç–æ–≤–∞—è", "—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–µ",
        "—Å–µ—Ä—ã–π", "—Å–µ—Ä–∞—è", "—Å–µ—Ä—ã–µ", "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–π", "—Å–µ—Ä–µ–±—Ä–∏—Å—Ç—ã–π",
        "–∑–æ–ª–æ—Ç–æ–π", "–∑–æ–ª–æ—Ç–∞—è",
        "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π", "–∫–æ—Ä–∏—á–Ω–µ–≤–∞—è",
        "–±–µ–∂–µ–≤—ã–π", "–±–µ–∂–µ–≤—ã–µ",
        "—Ö–∞–∫–∏", "–±–æ—Ä–¥–æ–≤—ã–π", "–º—è—Ç–Ω—ã–π", "–ø—É–¥—Ä–æ–≤—ã–π", "–±–∏—Ä—é–∑–æ–≤—ã–π",
        "—Ä–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–π", "–º–Ω–æ–≥–æ—Ü–≤–µ—Ç–Ω—ã–π", "–ø—ë—Å—Ç—Ä—ã–π", "–ø–µ—Å—Ç—Ä—ã–π"
    }
    COLOR_REGEX = re.compile(
        r"\b(" + "|".join(sorted(re.escape(word) for word in COLOR_KEYWORDS)) + r")\b",
        re.IGNORECASE
    )

    GENERIC_STOPWORDS = {
        "–≤–∞—Ä–∏–∞–Ω—Ç", "–≤–∞—Ä–∏–∞–Ω—Ç—ã", "–∫–æ–º–ø–ª–µ–∫—Ç", "–∫–æ–º–ø–ª–µ–∫—Ç—ã", "–Ω–∞–±–æ—Ä", "–Ω–∞–±–æ—Ä—ã",
        "–≤–µ—Ä—Å–∏–∏", "–≤–µ—Ä—Å–∏—è", "—Ç–∏–ø", "—Ç–∏–ø—ã", "–º–æ–¥–µ–ª—å", "–º–æ–¥–µ–ª–∏",
        "–¥–ª—è", "–∏–∑", "–æ—Ç", "–±–µ–∑", "–ø–æ–¥", "–Ω–∞", "–ø–æ", "–∏", "–∏–ª–∏", "—Å", "—Å–æ",
        "–≤", "–≤–æ", "—ç—Ç–æ", "—ç—Ç–æ—Ç", "—ç—Ç–∞", "—ç—Ç–∏", "–Ω–æ–≤—ã–π", "–Ω–æ–≤–∞—è", "–Ω–æ–≤—ã–µ",
        "—Ä–∞–∑–º–µ—Ä", "—Ä–∞–∑–º–µ—Ä—ã", "—Ü–≤–µ—Ç", "—Ü–≤–µ—Ç–∞"
    }

    BATTERY_KEYWORDS = ("–±–∞—Ç–∞—Ä", "battery", "power")
    CHARGE_KEYWORDS = ("–∑–∞—Ä—è–¥", "–∑–∞—Ä—è–∂–∞", "–∞–∫–∫—É–º", "recharge", "charging")
    def __init__(self):
        self.tmapi_client = TmapiClient()  # –ö–ª–∏–µ–Ω—Ç –¥–ª—è tmapi.top
        self.llm_client = get_llm_client()  # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π LLM –∫–ª–∏–µ–Ω—Ç (YandexGPT –∏–ª–∏ OpenAI)
        self.exchange_rate_client = ExchangeRateClient()  # –ö–ª–∏–µ–Ω—Ç –¥–ª—è ExchangeRate-API
        self.translation_client = get_translation_client()  # –û—Ç–¥–µ–ª—å–Ω—ã–π LLM –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤/–ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ü–µ–Ω
        # –î–ª—è ProxyAPI –æ—Ç–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö (JSON) –±–∞—Ç—á-–ø–µ—Ä–µ–≤–æ–¥–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –ª–∏—à–Ω–∏–π –±—é–¥–∂–µ—Ç
        # –∏ –Ω–µ –ø–æ–ª—É—á–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏.
        if isinstance(self.translation_client, ProxyAPIClient):
            self.translation_supports_structured = False
        else:
            self.translation_supports_structured = hasattr(self.translation_client, "generate_json_response")

    async def scrape_product(
        self, 
        url: str,
        user_signature: str = None,
        user_currency: str = None,
        exchange_rate: float = None
    ):
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ –ø–æ URL, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç.

        Args:
            url (str): URL —Ç–æ–≤–∞—Ä–∞ –¥–ª—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞.
            user_signature (str, optional): –ü–æ–¥–ø–∏—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ—Å—Ç–∞
            user_currency (str, optional): –í–∞–ª—é—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (cny –∏–ª–∏ rub)
            exchange_rate (float, optional): –ö—É—Ä—Å –æ–±–º–µ–Ω–∞ –¥–ª—è —Ä—É–±–ª—è

        Returns:
            tuple: –ö–æ—Ä—Ç–µ–∂, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ (str) –∏ —Å–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (list).
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        signature = user_signature or settings.DEFAULT_SIGNATURE
        currency = (user_currency or settings.DEFAULT_CURRENCY).lower()
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –∫—É—Ä—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        user_exchange_rate = exchange_rate if exchange_rate is not None else None
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã Pinduoduo –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–æ–º
        platform, _ = URLParser.parse_url(url)
        logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞: {platform} –¥–ª—è URL: {url}")
        
        if platform == Platform.PINDUODUO:
            logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ Pinduoduo —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥")
            pdd = PinduoduoWebScraper()
            api_response = await pdd.fetch_product(url)
            logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç Pinduoduo —Å–∫—Ä–µ–π–ø–µ—Ä–∞: code={api_response.get('code')}, msg={api_response.get('msg')}")
            api_response['_platform'] = Platform.PINDUODUO
        else:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ —á–µ—Ä–µ–∑ tmapi.top (–∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã)
            logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ TMAPI")
            api_response = await self.tmapi_client.get_product_info_auto(url)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É (–¥–æ–±–∞–≤–ª–µ–Ω–æ –º–µ—Ç–æ–¥–æ–º get_product_info_auto)
        platform = api_response.get('_platform', 'unknown')
        
        # TMAPI –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É: {"code": 200, "msg": "success", "data": {...}}
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ –ø–æ–ª—è "data"
        if isinstance(api_response, dict) and 'data' in api_response:
            product_data = api_response['data']
        else:
            product_data = api_response
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –≤ product_data –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        product_data['_platform'] = platform

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø–æ—Å—Ç–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π URL, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        try:
            if platform == Platform.PINDUODUO:
                # pinduoduo_web –∫–ª–∞–¥—ë—Ç –∫–æ—Ä–æ—Ç–∫–∏–π URL –≤ data.url
                short_url = product_data.get('url') or product_data.get('pdd_minimal', {}).get('url')
                if short_url:
                    product_data['product_url'] = short_url
        except Exception:
            pass
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {platform}")
            print(f"[Scraper] –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞ –ø–æ–ª—É—á–µ–Ω—ã: {product_data.get('title', 'N/A')[:50]}...")
        
        # –†–∞–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ Pinduoduo –∏ –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (401) ‚Äî —Å–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        if platform == 'pinduoduo':
            logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ Pinduoduo: code={api_response.get('code') if isinstance(api_response, dict) else 'N/A'}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫—É –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            if isinstance(api_response, dict) and api_response.get('code') == 401:
                logger.warning("–û—à–∏–±–∫–∞ 401: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç cookies –¥–ª—è Pinduoduo")
                user_msg = (
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞ —Å Pinduoduo.\n\n"
                    "‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª —Å cookies –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.\n\n"
                    "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å Pinduoduo –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ:\n"
                    "1. –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª `src/pdd_cookies.json` –Ω–∞ –æ—Å–Ω–æ–≤–µ `src/pdd_cookies_example.json`\n"
                    "2. –ó–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–∞–π–ª —Ä–µ–∞–ª—å–Ω—ã–º–∏ cookies –∏–∑ –≤–∞—à–µ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞\n"
                    "3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞\n\n"
                    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ —Å–º. –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞."
                )
                return user_msg, []
            # –†–∞–Ω–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ Pinduoduo –∏ —Å–æ–≤—Å–µ–º –ø—É—Å—Ç–æ ‚Äî –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–µ–ø–æ—á–∫—É –¥–æ LLM
            no_images = not product_data.get('main_imgs') and not product_data.get('detail_imgs')
            no_text = not (product_data.get('details') or product_data.get('title'))
            logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö Pinduoduo: images={not no_images}, text={not no_text}")
            if no_images and no_text:
                logger.warning("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç Pinduoduo: –Ω–µ—Ç —Ñ–æ—Ç–æ –∏ –æ–ø–∏—Å–∞–Ω–∏—è")
                if settings.DEBUG_MODE:
                    print("[Scraper][Pinduoduo] –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –Ω–µ—Ç —Ñ–æ—Ç–æ –∏ –æ–ø–∏—Å–∞–Ω–∏—è. –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–µ–ø–æ—á–∫—É.")
                    print(f"[Scraper][Pinduoduo] product_data keys: {list(product_data.keys())}")
                user_msg = (
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞ —Å Pinduoduo.\n\n"
                    "–í–æ–∑–º–æ–∂–Ω–æ, —É—Å—Ç–∞—Ä–µ–ª–∏ cookies / User-Agent, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç—Ä–µ–±—É–µ—Ç –∫–∞–ø—á—É/–ª–æ–≥–∏–Ω –∏–ª–∏ –¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω.\n"
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –æ–±–Ω–æ–≤–∏—Ç–µ cookies."
                )
                return user_msg, []
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —á–µ—Ä–µ–∑ Yandex Translate –ø–µ—Ä–µ–¥ LLM
            try:
                pdd_min = product_data.get('pdd_minimal', {}) if isinstance(product_data, dict) else {}
                raw_description = (
                    (pdd_min.get('description') or '').strip() or
                    (product_data.get('details') or '').strip() or
                    (product_data.get('title') or '').strip()
                )
                if raw_description:
                    translated = await self._translate_text_generic(raw_description, target_language="ru")
                    if translated and translated != raw_description:
                        product_data['details'] = translated
                        if settings.DEBUG_MODE:
                            print(f"[Scraper][Pinduoduo] –ü–µ—Ä–µ–≤–æ–¥ –æ–ø–∏—Å–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω, –¥–ª–∏–Ω–∞: {len(translated)}")
            except Exception as e:
                if settings.DEBUG_MODE:
                    print(f"[Scraper][Pinduoduo] –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {e}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—É—Ä—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –æ–Ω –ø–µ—Ä–µ–¥–∞–Ω, –∏–Ω–∞—á–µ –ø–æ–ª—É—á–∞–µ–º –∏–∑ API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        exchange_rate = user_exchange_rate
        if exchange_rate is None and settings.CONVERT_CURRENCY:
            exchange_rate = await self.exchange_rate_client.get_exchange_rate()

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM (–±–µ–∑ –æ–≥—Ä–æ–º–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞ skus!)
        compact_data = self._prepare_compact_data_for_llm(product_data)

        # –ó–∞–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ü–µ–Ω
        raw_title = product_data.get('title', '') or ''
        translated_title_hint = await self._translate_text_generic(raw_title, target_language="ru")
        if translated_title_hint:
            compact_data["title_hint"] = translated_title_hint
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        raw_description = ''
        platform = product_data.get('_platform')
        if platform == 'pinduoduo':
            pdd_min = product_data.get('pdd_minimal', {}) if isinstance(product_data, dict) else {}
            raw_description = (
                (pdd_min.get('description') or '').strip() or
                (product_data.get('details') or '').strip()
            )
        else:
            raw_description = (product_data.get('details') or '').strip()
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
        translated_description = ''
        if raw_description:
            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            description_sample = raw_description[:500]
            translated_description = await self._translate_text_generic(description_sample, target_language="ru")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ü–µ–Ω
        product_context = {
            'title': translated_title_hint or raw_title,
            'description': translated_description
        }

        price_lines = await self._prepare_price_entries(product_data, product_context)
        if price_lines:
            compact_data["translated_sku_prices"] = price_lines
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ LLM
        # LLM –≤–µ—Ä–Ω–µ—Ç JSON —Å: title, description, characteristics, hashtags
        llm_content = await self.llm_client.generate_post_content(compact_data)
        translated_title = llm_content.get('title') or translated_title_hint
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] LLM –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω: {llm_content.get('title', 'N/A')}")
        
        # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –≤ —Ü–µ–Ω–∞—Ö –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        if price_lines and llm_content:
            price_lines = self._fix_price_labels_with_context(price_lines, llm_content)
        
        # –°–∞–Ω–∏—Ç–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM: —É–±–∏—Ä–∞–µ–º –≤—ã–¥—É–º–∞–Ω–Ω—ã–µ ¬´–¶–≤–µ—Ç–∞¬ª, –¥–æ–±–∞–≤–ª—è–µ–º/—Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–°–æ—Å—Ç–∞–≤¬ª
        try:
            if isinstance(llm_content, dict):
                mc = llm_content.get('main_characteristics') or {}
                if not isinstance(mc, dict):
                    mc = {}
                looks_like_apparel = self._is_apparel_product(translated_title or translated_title_hint, product_data)
                # 1) –£–¥–∞–ª—è–µ–º —Ü–≤–µ—Ç–∞, –µ—Å–ª–∏ LLM –≤—ã–¥—É–º–∞–ª –≤—Ä–æ–¥–µ ¬´–ß–∏—Å—Ç—ã–π —Ü–≤–µ—Ç¬ª/¬´–û–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π¬ª
                colors = mc.get('–¶–≤–µ—Ç–∞') or mc.get('–¶–≤–µ—Ç')
                if colors:
                    bad_markers = {'—á–∏—Å—Ç—ã–π —Ü–≤–µ—Ç', '–æ–¥–Ω–æ—Ç–æ–Ω', '–æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π', 'plain', 'solid'}
                    def _is_bad(val: str) -> bool:
                        s = (val or '').strip().lower()
                        return any(k in s for k in bad_markers)
                    if isinstance(colors, list):
                        filtered = [c for c in colors if isinstance(c, str) and not _is_bad(c)]
                        if filtered:
                            mc['–¶–≤–µ—Ç–∞'] = filtered
                        else:
                            mc.pop('–¶–≤–µ—Ç–∞', None)
                    elif isinstance(colors, str) and _is_bad(colors):
                        mc.pop('–¶–≤–µ—Ç–∞', None)
                if not looks_like_apparel:
                    mc.pop('–¶–≤–µ—Ç–∞', None)
                    mc.pop('–¶–≤–µ—Ç', None)
                # 2) –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å–µ–∫—Ü–∏–∏ ¬´–í–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–±–æ—Ä–æ–≤¬ª, ¬´–ö–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏¬ª –∏ —Ç.–ø.
                forbidden_sections = ('–≤–∞—Ä–∏–∞–Ω—Ç', '–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü', '–Ω–∞–±–æ—Ä')
                for key in list(mc.keys()):
                    if any(token in key.lower() for token in forbidden_sections):
                        mc.pop(key, None)
                # 3) –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º ¬´–°–æ—Å—Ç–∞–≤¬ª, –µ—Å–ª–∏ –æ–Ω —è–≤–Ω—ã–º –æ–±—Ä–∞–∑–æ–º —É–∫–∞–∑–∞–Ω –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
                platform = product_data.get('_platform')
                if platform == 'pinduoduo':
                    import re
                    desc_text = (product_data.get('details') or '')
                    comp = None
                    # –ò—â–µ–º ¬´–¢–∫–∞–Ω—å/–º–∞—Ç–µ—Ä–∏–∞–ª¬ª, ¬´–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–æ–ª–æ–∫–æ–Ω¬ª, ¬´–°–æ—Å—Ç–∞–≤¬ª
                    for pat in [r"(?i)–°–æ—Å—Ç–∞–≤[:Ôºö]\s*([^\n]+)", r"(?i)–¢–∫–∞–Ω—å\s*/?\s*–º–∞—Ç–µ—Ä–∏–∞–ª[:Ôºö]\s*([^\n]+)", r"(?i)–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–æ–ª–æ–∫–æ–Ω[:Ôºö]\s*([^\n]+)"]:
                        m = re.search(pat, desc_text)
                        if m:
                            comp = m.group(1).strip()
                            break
                    if comp:
                        if not str(mc.get('–°–æ—Å—Ç–∞–≤') or '').strip():
                            mc['–°–æ—Å—Ç–∞–≤'] = comp
                llm_content['main_characteristics'] = mc
        except Exception:
            pass
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        post_text = self._build_post_text(
            llm_content=llm_content,
            product_data=product_data,
            signature=signature,
            currency=currency,
            exchange_rate=exchange_rate,
            price_lines=price_lines
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        if platform == 'pinduoduo':
            # –î–ª—è Pinduoduo: main_imgs + detail_imgs (–Ω–µ—Ç sku_props)
            sku_images = product_data.get('main_imgs', [])
            
            # –£ Pinduoduo detail_imgs —É–∂–µ –µ—Å—Ç—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ—Ç–≤–µ—Ç–µ
            detail_images = product_data.get('detail_imgs', [])
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] Pinduoduo: main_imgs={len(sku_images)}, detail_imgs={len(detail_images)}")
        else:
            # –î–ª—è Taobao/Tmall: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º main_imgs –∏ sku_props
            sku_images = self._get_unique_images_from_sku_props(product_data)
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ item_desc
            item_id = product_data.get('item_id')
            detail_images = []
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] –ò–∑–≤–ª–µ—á–µ–Ω item_id: {item_id}")
            
            if item_id:
                detail_images = await self._get_filtered_detail_images(item_id)
                if settings.DEBUG_MODE:
                    print(f"[Scraper] –ü–æ–ª—É—á–µ–Ω–æ detail –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(detail_images)}")
            else:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] ‚ö†Ô∏è item_id –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç! –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ detail –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: —Å–Ω–∞—á–∞–ª–∞ –∏–∑ sku_props, –ø–æ—Ç–æ–º –∏–∑ detail_html
        image_urls = sku_images + detail_images
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ò—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_urls)} (sku: {len(sku_images)}, detail: {len(detail_images)})")

        return post_text, image_urls
    
    def _prepare_compact_data_for_llm(self, product_data: dict) -> dict:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ LLM.
        –£–±–∏—Ä–∞–µ—Ç –æ–≥—Ä–æ–º–Ω—ã–π –º–∞—Å—Å–∏–≤ skus –∏ –¥—Ä—É–≥–∏–µ –ª–∏—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ Taobao/Tmall, —Ç–∞–∫ –∏ Pinduoduo.
        
        Args:
            product_data: –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç TMAPI
            
        Returns:
            dict: –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ —Å –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        platform = product_data.get('_platform', 'unknown')
        
        compact = {
            'title': product_data.get('title', ''),
            'product_props': product_data.get('product_props', [])
        }
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
        if platform == 'pinduoduo':
            # –î–ª—è Pinduoduo: –∏–∑–≤–ª–µ–∫–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ skus (props_names)
            skus = product_data.get('skus', [])
            colors = set()
            sizes = set()
            
            for sku in skus[:50]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 50 SKU
                props_names = sku.get('props_names', '')
                # –§–æ—Ä–º–∞—Ç: "ÂûãÂè∑:ÁªèÊµéÊ¨æ;Â•óÈ§ê:Á§ºÂåÖ‰∏Ä"
                if props_names:
                    props_parts = props_names.split(';')
                    for part in props_parts:
                        if ':' in part:
                            key, value = part.split(':', 1)
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –∏–ª–∏ —Ä–∞–∑–º–µ—Ä –ø–æ –∫–ª—é—á—É
                            if 'È¢úËâ≤' in key or 'color' in key.lower() or 'Ëâ≤' in key:
                                colors.add(value)
                            elif 'Â∞∫Á†Å' in key or 'size' in key.lower() or 'ÂûãÂè∑' in key:
                                sizes.add(value)
            
            if colors:
                compact['available_colors'] = list(colors)[:20]
            if sizes:
                compact['available_sizes'] = list(sizes)[:30]
        else:
            # –î–ª—è Taobao/Tmall: –∏—Å–ø–æ–ª—å–∑—É–µ–º sku_props
            sku_props = product_data.get('sku_props', [])
            if sku_props:
                for prop in sku_props:
                    prop_name = prop.get('prop_name', '')
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–≤–µ—Ç–∞
                    if '—Ü–≤–µ—Ç' in prop_name.lower() or 'color' in prop_name.lower():
                        colors = [v.get('name', '') for v in prop.get('values', [])]
                        if colors:
                            compact['available_colors'] = colors[:20]
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã
                    if '—Ä–∞–∑–º–µ—Ä' in prop_name.lower() or 'size' in prop_name.lower() or 'Â∞∫Á†Å' in prop_name:
                        sizes = [v.get('name', '') for v in prop.get('values', [])]
                        if sizes:
                            compact['available_sizes'] = sizes[:30]
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã. –†–∞–∑–º–µ—Ä: ~{len(str(compact))} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"[Scraper] –ò—Å–∫–ª—é—á–µ–Ω–æ {len(product_data.get('skus', []))} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ skus")
        
        return compact
    
    def _get_unique_images_from_sku_props(self, product_data: dict) -> list:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤—ã–±–∏—Ä–∞—è –ª—É—á—à–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫.
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ main_imgs –∏ sku_props.
        –ë–µ—Ä–µ—Ç –æ—Ç–∫—É–¥–∞ –±–æ–ª—å—à–µ. –ï—Å–ª–∏ —Ä–∞–≤–Ω–æ - –±–µ—Ä–µ—Ç –∏–∑ main_imgs.
        
        Args:
            product_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞ –æ—Ç TMAPI
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ª—É—á—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ main_imgs
        main_imgs = product_data.get('main_imgs', [])
        main_imgs_count = len(main_imgs) if main_imgs else 0
        
        # –ü–æ–ª—É—á–∞–µ–º sku_props
        sku_props = product_data.get('sku_props', [])
        
        if not sku_props:
            # –ï—Å–ª–∏ –Ω–µ—Ç sku_props, –∏—Å–ø–æ–ª—å–∑—É–µ–º main_imgs
            if settings.DEBUG_MODE:
                print(f"[Scraper] sku_props –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º main_imgs ({main_imgs_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
            return main_imgs
        
        # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ sku_props
        sku_unique_images = []
        seen_urls = set()
        
        for prop in sku_props:
            values = prop.get('values', [])
            
            for value in values:
                image_url = value.get('imageUrl', '').strip()
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏ –Ω–µ–ø—É—Å—Ç—ã–µ URL
                if image_url and image_url not in seen_urls:
                    seen_urls.add(image_url)
                    sku_unique_images.append(image_url)
        
        sku_props_count = len(sku_unique_images)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if sku_props_count > main_imgs_count:
            # –í sku_props –±–æ–ª—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if settings.DEBUG_MODE:
                print(f"[Scraper] sku_props: {sku_props_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π > main_imgs: {main_imgs_count} ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º sku_props")
            return sku_unique_images
        elif main_imgs_count > sku_props_count:
            # –í main_imgs –±–æ–ª—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if settings.DEBUG_MODE:
                print(f"[Scraper] main_imgs: {main_imgs_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π > sku_props: {sku_props_count} ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º main_imgs")
            return main_imgs
        else:
            # –†–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç main_imgs
            if settings.DEBUG_MODE:
                print(f"[Scraper] main_imgs: {main_imgs_count} = sku_props: {sku_props_count} ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º main_imgs (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)")
            return main_imgs if main_imgs else sku_unique_images
    
    async def _get_filtered_detail_images(self, item_id: int) -> list:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ item_desc –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º.
        –£–±–∏—Ä–∞–µ—Ç –±–∞–Ω–Ω–µ—Ä—ã –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –≥—Ä—É–ø–ø—ã.
        
        Args:
            item_id: ID —Ç–æ–≤–∞—Ä–∞
            
        Returns:
            list: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        try:
            if settings.DEBUG_MODE:
                print(f"[Scraper] –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º item_desc –¥–ª—è item_id={item_id}")
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            desc_data = await self.tmapi_client.get_item_description(item_id)
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] item_desc –æ—Ç–≤–µ—Ç: code={desc_data.get('code')}, data keys={list(desc_data.get('data', {}).keys()) if desc_data.get('data') else 'None'}")
            
            if not desc_data or desc_data.get('code') != 200:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å item_desc. –ö–æ–¥: {desc_data.get('code') if desc_data else 'None'}")
                    print(f"[Scraper] –û—Ç–≤–µ—Ç API: {desc_data}")
                return []
            
            detail_html = desc_data.get('data', {}).get('detail_html', '')
            
            if settings.DEBUG_MODE:
                html_len = len(detail_html) if detail_html else 0
                print(f"[Scraper] detail_html –¥–ª–∏–Ω–∞: {html_len} —Å–∏–º–≤–æ–ª–æ–≤")
                if html_len > 0:
                    print(f"[Scraper] detail_html –Ω–∞—á–∞–ª–æ: {detail_html[:200]}...")
            
            if not detail_html:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] ‚ö†Ô∏è detail_html –ø—É—Å—Ç!")
                return []
            
            # –ü–∞—Ä—Å–∏–º HTML —Å—Ç—Ä–æ–∫—É –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images_with_sizes, images_urls_only = self._parse_detail_html(detail_html)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å URL –±–µ–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
            if images_urls_only:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è {len(images_urls_only)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
                
                images_from_urls = await self._get_image_sizes_from_urls(images_urls_only)
                images_with_sizes.extend(images_from_urls)
            
            if not images_with_sizes:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏")
                return []
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏: {len(images_with_sizes)}")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            filtered_images = self._filter_images_by_size(images_with_sizes)
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] Detail –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images_with_sizes)} ‚Üí {len(filtered_images)} –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            
            return [img['url'] for img in filtered_images]
            
        except Exception as e:
            if settings.DEBUG_MODE:
                import traceback
                print(f"[Scraper] ‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ detail –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
                print(f"[Scraper] –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
                print(f"[Scraper] –°–æ–æ–±—â–µ–Ω–∏–µ: {e}")
                print(f"[Scraper] Traceback:")
                traceback.print_exc()
            return []
    
    def _parse_detail_html(self, detail_html: str) -> list:
        """
        –ü–∞—Ä—Å–∏—Ç HTML —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–≥–∞–º–∏ <img> –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç URL.
        –ï—Å–ª–∏ –∞—Ç—Ä–∏–±—É—Ç size –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ, –∏–Ω–∞—á–µ –ø–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –ø–æ URL.
        
        Args:
            detail_html: HTML —Å—Ç—Ä–æ–∫–∞ —Å —Ç–µ–≥–∞–º–∏ <img>
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å url, width, height
        """
        import re
        
        images_with_sizes = []
        images_urls_only = []
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–µ–≥–∏ <img>
        img_tags = re.findall(r'<img[^>]*>', detail_html, re.IGNORECASE)
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ù–∞–π–¥–µ–Ω–æ {len(img_tags)} —Ç–µ–≥–æ–≤ <img> –≤ HTML")
        
        for img_tag in img_tags:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º src
            src_match = re.search(r'src="([^"]+)"', img_tag, re.IGNORECASE)
            if not src_match:
                continue
            
            url = src_match.group(1).strip()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å size (–µ—Å–ª–∏ –µ—Å—Ç—å)
            size_match = re.search(r'size="(\d+)x(\d+)"', img_tag, re.IGNORECASE)
            
            if size_match:
                try:
                    width = int(size_match.group(1))
                    height = int(size_match.group(2))
                    
                    if width > 0 and height > 0:
                        images_with_sizes.append({
                            'url': url,
                            'width': width,
                            'height': height
                        })
                except ValueError:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å size: {size_match.group(1)}x{size_match.group(2)}")
            else:
                # –ù–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞ size - —Å–æ—Ö—Ä–∞–Ω—è–µ–º URL –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
                images_urls_only.append(url)
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –° –∞—Ç—Ä–∏–±—É—Ç–æ–º size: {len(images_with_sizes)}")
            print(f"[Scraper] –ë–µ–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ size: {len(images_urls_only)}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–∞ —Å–ø–∏—Å–∫–∞ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        return images_with_sizes, images_urls_only
    
    async def _get_image_sizes_from_urls(self, urls: list) -> list:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ URL.
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ 5 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏.
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å url, width, height
        """
        import asyncio
        
        images_with_sizes = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Ä—Ü–∏—è–º–∏ –ø–æ 5 –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
        batch_size = 5
        
        for i in range(0, len(urls), batch_size):
            batch = urls[i:i+batch_size]
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Ä—Ü–∏—é {i//batch_size + 1}/{(len(urls) + batch_size - 1)//batch_size} ({len(batch)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)...")
                print(f"[Scraper] URLs –≤ —ç—Ç–æ–π –ø–æ—Ä—Ü–∏–∏:")
                for idx, url in enumerate(batch):
                    print(f"[Scraper]   {idx+1}. {url[:100]}...")
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ—Ä—Ü–∏–∏
            tasks = [self._get_single_image_size(url) for url in batch]
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] –°–æ–∑–¥–∞–Ω–æ {len(tasks)} –∑–∞–¥–∞—á, –∑–∞–ø—É—Å–∫–∞–µ–º asyncio.gather()...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            if settings.DEBUG_MODE:
                print(f"[Scraper] asyncio.gather() –∑–∞–≤–µ—Ä—à—ë–Ω, –ø–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                print(f"[Scraper] –¢–∏–ø—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {[type(r).__name__ for r in results]}")
            
            # –°–æ–±–∏—Ä–∞–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for idx, result in enumerate(results):
                if isinstance(result, dict) and 'url' in result:
                    images_with_sizes.append(result)
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç {idx+1}: {result['width']}x{result['height']}")
                elif isinstance(result, Exception):
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç {idx+1}: Exception - {type(result).__name__}: {result}")
                elif result is None:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç {idx+1}: None")
                else:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç {idx+1}: {type(result).__name__} = {result}")
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è {len(images_with_sizes)} –∏–∑ {len(urls)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        return images_with_sizes
    
    async def _get_single_image_size(self, url: str) -> dict:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL.
        –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ—Ç—Å—è Range –∑–∞–ø—Ä–æ—Å (4KB), –µ—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é (—Å –ª–∏–º–∏—Ç–æ–º).
        
        Args:
            url: URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å url, width, height –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if settings.DEBUG_MODE:
            print(f"[Scraper] >>> –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É: {url[:80]}...")
        
        import httpx
        from PIL import Image
        from io import BytesIO
        
        try:
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ Alibaba CDN (HTTP 420)
            browser_headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Referer': 'https://item.taobao.com/',
                'Sec-Fetch-Dest': 'image',
                'Sec-Fetch-Mode': 'no-cors',
                'Sec-Fetch-Site': 'cross-site',
            }
            
            async with httpx.AsyncClient(timeout=10.0, follow_redirects=True, headers=browser_headers) as client:
                # –ü–æ–ø—ã—Ç–∫–∞ 1: Range –∑–∞–ø—Ä–æ—Å (—ç–∫–æ–Ω–æ–º–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞)
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 64KB –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ JPEG/PNG
                headers = {'Range': 'bytes=0-65535'}  # 64KB –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                
                try:
                    response = await client.get(url, headers=headers)
                    
                    if settings.DEBUG_MODE:
                        content_range = response.headers.get('Content-Range', '–Ω–µ—Ç')
                        print(f"[Scraper] üîç Range –∑–∞–ø—Ä–æ—Å: HTTP {response.status_code}, —Ä–∞–∑–º–µ—Ä: {len(response.content)} –±–∞–π—Ç, Content-Range: {content_range}")
                    
                    if response.status_code in (200, 206):  # 200 = –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª, 206 = —á–∞—Å—Ç—å
                        try:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
                            img = Image.open(BytesIO(response.content))
                            width, height = img.size
                            
                            if width > 0 and height > 0:
                                # –î–ª—è Range –∑–∞–ø—Ä–æ—Å–∞ file_size –±–µ—Ä—ë–º –∏–∑ Content-Range (—Ñ–æ—Ä–º–∞—Ç: "bytes 0-65535/150000")
                                file_size = 0
                                content_range = response.headers.get('Content-Range', '')
                                if content_range:
                                    # –ü–∞—Ä—Å–∏–º "bytes 0-65535/150000" -> –±–µ—Ä—ë–º 150000
                                    parts = content_range.split('/')
                                    if len(parts) == 2:
                                        try:
                                            file_size = int(parts[1])
                                        except ValueError:
                                            pass
                                
                                if settings.DEBUG_MODE:
                                    if file_size > 0:
                                        print(f"[Scraper] ‚úÖ Range –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω: {width}x{height}, –ø–æ–ª–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {file_size/1024:.1f}KB")
                                    else:
                                        print(f"[Scraper] ‚úÖ Range –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω: {width}x{height} (—Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω)")
                                return {
                                    'url': url,
                                    'width': width,
                                    'height': height,
                                    'file_size': file_size
                                }
                        except Exception as pil_error:
                            if settings.DEBUG_MODE:
                                print(f"[Scraper] ‚ö†Ô∏è Range –∑–∞–ø—Ä–æ—Å: PIL –Ω–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {type(pil_error).__name__}")
                    
                except Exception as range_error:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ö†Ô∏è Range –∑–∞–ø—Ä–æ—Å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {type(range_error).__name__}: {range_error}")
                
                # –ü–æ–ø—ã—Ç–∫–∞ 2: –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (—Å –ª–∏–º–∏—Ç–æ–º 2MB –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤)
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç, —Ç–∞–∫ –∫–∞–∫ –º–Ω–æ–≥–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è Taobao –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä 500-700KB
                if settings.DEBUG_MODE:
                    print(f"[Scraper] üîÑ –ü—Ä–æ–±—É–µ–º –ø–æ–ª–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É...")
                
                response = await client.get(url)
                
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –Ω–µ –±–æ–ª–µ–µ 2MB (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)
                # –ë–æ–ª—å—à–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (>2MB) –æ–±—ã—á–Ω–æ —è–≤–ª—è—é—Ç—Å—è –±–∞–Ω–Ω–µ—Ä–∞–º–∏ –∏–ª–∏ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏
                if len(response.content) > 2 * 1024 * 1024:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {len(response.content)/1024:.1f}KB (–ª–∏–º–∏—Ç 2MB)")
                    return None
                
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤
                    img = Image.open(BytesIO(response.content))
                    width, height = img.size
                    
                    if width > 0 and height > 0:
                        file_size = len(response.content)
                        if settings.DEBUG_MODE:
                            print(f"[Scraper] ‚úÖ –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞: {width}x{height}, —Ä–∞–∑–º–µ—Ä: {file_size/1024:.1f}KB")
                        return {
                            'url': url,
                            'width': width,
                            'height': height,
                            'file_size': file_size
                        }
                    else:
                        if settings.DEBUG_MODE:
                            print(f"[Scraper] ‚ùå PIL –≤–µ—Ä–Ω—É–ª {width}x{height}")
                        return None
                except Exception as pil_error:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] ‚ùå PIL –Ω–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {type(pil_error).__name__}: {pil_error}")
                    return None
                    
        except Exception as e:
            if settings.DEBUG_MODE:
                print(f"[Scraper] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞:")
                print(f"[Scraper]    URL: {url[:100]}...")
                print(f"[Scraper]    –¢–∏–ø: {type(e).__name__}")
                print(f"[Scraper]    –°–æ–æ–±—â–µ–Ω–∏–µ: {e}")
            return None
    
    def _filter_images_by_size(self, images_with_sizes: list) -> list:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º.
        –£–±–∏—Ä–∞–µ—Ç –±–∞–Ω–Ω–µ—Ä—ã, –∏–∫–æ–Ω–∫–∏/–∫–Ω–æ–ø–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞.
        
        Args:
            images_with_sizes: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å url, width, height, file_size (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            list: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        import statistics
        
        if not images_with_sizes:
            return []
        
        # –®–∞–≥ 1: –£–±–∏—Ä–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–∫–æ–Ω–∫–∏, –∫–Ω–æ–ø–∫–∏)
        min_dimension = 150  # –ú–∏–Ω–∏–º—É–º 150x150
        large_enough = []
        
        for img in images_with_sizes:
            width = img['width']
            height = img['height']
            
            if width >= min_dimension and height >= min_dimension:
                large_enough.append(img)
            elif settings.DEBUG_MODE:
                print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ: {width}x{height} (–º–∏–Ω–∏–º—É–º {min_dimension}x{min_dimension})")
        
        if not large_enough:
            if settings.DEBUG_MODE:
                print(f"[Scraper] ‚ö†Ô∏è –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ")
            return []
        
        # –®–∞–≥ 2: –£–±–∏—Ä–∞–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        min_file_size = 20 * 1024  # –ú–∏–Ω–∏–º—É–º 20KB
        size_filtered = []
        
        for img in large_enough:
            file_size = img.get('file_size', 0)
            
            if file_size == 0:
                # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω - –æ—Å—Ç–∞–≤–ª—è–µ–º (—Å–µ—Ä–≤–µ—Ä –Ω–µ –≤–µ—Ä–Ω—É–ª Content-Range)
                size_filtered.append(img)
                if settings.DEBUG_MODE:
                    print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤–µ—Å–∞ –¥–ª—è {img['width']}x{img['height']} (—Ä–∞–∑–º–µ—Ä –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω)")
            elif file_size >= min_file_size:
                size_filtered.append(img)
            else:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –ª—ë–≥–∫–æ–µ: {img['width']}x{img['height']} ({file_size/1024:.1f}KB < {min_file_size/1024:.0f}KB)")
        
        if not size_filtered:
            if settings.DEBUG_MODE:
                print(f"[Scraper] ‚ö†Ô∏è –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –ª—ë–≥–∫–∏–µ")
            return []
        
        # –®–∞–≥ 3: –£–±–∏—Ä–∞–µ–º —è–≤–Ω—ã–µ –±–∞–Ω–Ω–µ—Ä—ã (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω > 5:1 –∏–ª–∏ < 1:5)
        non_banners = []
        for img in size_filtered:
            width = img['width']
            height = img['height']
            aspect_ratio = width / height if height > 0 else 0
            
            # –ï—Å–ª–∏ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ—Ç 0.2 –¥–æ 5.0 - —ç—Ç–æ –ù–ï –±–∞–Ω–Ω–µ—Ä
            if 0.2 <= aspect_ratio <= 5.0:
                non_banners.append(img)
            elif settings.DEBUG_MODE:
                print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∞–Ω–Ω–µ—Ä: {width}x{height} (aspect: {aspect_ratio:.2f})")
        
        if not non_banners:
            if settings.DEBUG_MODE:
                print(f"[Scraper] ‚ö†Ô∏è –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –±–∞–Ω–Ω–µ—Ä—ã")
            return []
        
        # –®–∞–≥ 4: –ù–∞—Ö–æ–¥–∏–º –º–µ–¥–∏–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–ø–ª–æ—â–∞–¥—å)
        areas = [img['width'] * img['height'] for img in non_banners]
        median_area = statistics.median(areas)
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ú–µ–¥–∏–∞–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å: {median_area:,.0f} –ø–∏–∫—Å–µ–ª–µ–π")
        
        # –®–∞–≥ 5: –£–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –º–µ–¥–∏–∞–Ω—ã –ø–æ –ø–ª–æ—â–∞–¥–∏
        # –£–ñ–ï–°–¢–û–ß–ï–ù–ù–´–ô –¥–æ–ø—É—Å–∫: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 0.6x - 1.7x –æ—Ç –º–µ–¥–∏–∞–Ω—ã
        area_filtered = []
        for img in non_banners:
            area = img['width'] * img['height']
            ratio = area / median_area if median_area > 0 else 0
            
            if 0.6 <= ratio <= 1.7:
                area_filtered.append(img)
            elif settings.DEBUG_MODE:
                print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img['width']}x{img['height']} (–ø–ª–æ—â–∞–¥—å –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –≤ {ratio:.2f}x –æ—Ç –º–µ–¥–∏–∞–Ω—ã)")
        
        if not area_filtered:
            if settings.DEBUG_MODE:
                print(f"[Scraper] ‚ö†Ô∏è –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –ø–æ –ø–ª–æ—â–∞–¥–∏")
            return []
        
        # –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å aspect ratio (—á—Ç–æ–±—ã –æ—Ç—Å–µ—è—Ç—å –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ —Å—Ä–µ–¥–∏ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã—Ö –∏ –Ω–∞–æ–±–æ—Ä–æ—Ç)
        aspect_ratios = [img['width'] / img['height'] if img['height'] > 0 else 0 for img in area_filtered]
        median_aspect = statistics.median(aspect_ratios)
        
        if settings.DEBUG_MODE:
            print(f"[Scraper] –ú–µ–¥–∏–∞–Ω–Ω—ã–π aspect ratio: {median_aspect:.2f}")
        
        filtered = []
        for img in area_filtered:
            aspect = img['width'] / img['height'] if img['height'] > 0 else 0
            # –ï—Å–ª–∏ –º–µ–¥–∏–∞–Ω–Ω—ã–π aspect ~0.77 (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ), —Ç–æ –¥–æ–ø—É—Å–∫–∞–µ–º 0.5-1.5
            # –ï—Å–ª–∏ –º–µ–¥–∏–∞–Ω–Ω—ã–π aspect ~1.0 (–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ), —Ç–æ –¥–æ–ø—É—Å–∫–∞–µ–º 0.7-1.4
            # –ï—Å–ª–∏ –º–µ–¥–∏–∞–Ω–Ω—ã–π aspect ~1.5 (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ), —Ç–æ –¥–æ–ø—É—Å–∫–∞–µ–º 1.0-2.0
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: ¬±40% –æ—Ç –º–µ–¥–∏–∞–Ω—ã
            min_aspect = median_aspect * 0.6
            max_aspect = median_aspect * 1.4
            
            if min_aspect <= aspect <= max_aspect:
                filtered.append(img)
            elif settings.DEBUG_MODE:
                print(f"[Scraper] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img['width']}x{img['height']} (aspect {aspect:.2f} –Ω–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {min_aspect:.2f}-{max_aspect:.2f})")
        
        if settings.DEBUG_MODE and filtered:
            sizes = [f"{img['width']}x{img['height']}" for img in filtered]
            print(f"[Scraper] ‚úÖ –ü—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä: {', '.join(sizes)}")
        
        return filtered
    
    def _get_max_price_from_skus(self, product_data: dict) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –∏–∑ skus –≥–¥–µ stock > 0.
        
        Args:
            product_data: –î–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞ –æ—Ç TMAPI
            
        Returns:
            str: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∏–ª–∏ —Ü–µ–Ω–∞ –∏–∑ price_info
        """
        skus = product_data.get('skus', [])
        
        if not skus:
            # –ï—Å–ª–∏ skus –Ω–µ—Ç, –±–µ—Ä–µ–º –∏–∑ price_info
            return product_data.get('price_info', {}).get('price', 'N/A')
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º skus —Å stock > 0
        available_skus = [sku for sku in skus if sku.get('stock', 0) > 0]
        
        if not available_skus:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö, –±–µ—Ä–µ–º –∏–∑ price_info
            return product_data.get('price_info', {}).get('price', 'N/A')
        
        # –ò—â–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é sale_price
        max_price = None
        for sku in available_skus:
            sale_price = sku.get('sale_price')
            if sale_price is not None:
                try:
                    price_value = float(sale_price)
                    if max_price is None or price_value > max_price:
                        max_price = price_value
                except (ValueError, TypeError):
                    continue
        
        if max_price is not None:
            if settings.DEBUG_MODE:
                print(f"[Scraper] –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∏–∑ skus: {max_price}")
            return str(max_price)
        
        # Fallback –Ω–∞ price_info
        return product_data.get('price_info', {}).get('price', 'N/A')

    def _fix_price_labels_with_context(self, price_lines: list[dict], llm_content: dict) -> list[dict]:
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±—â–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö —Ü–µ–Ω –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∏–ø—ã —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è LLM.
        
        –ù–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–º–µ–Ω—è–µ—Ç "–≤–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞" –Ω–∞ "—Ä—É–±–∞—à–∫–∞", –µ—Å–ª–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è "—Ä—É–±–∞—à–∫–∞".
        """
        if not price_lines or not llm_content:
            return price_lines
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
        description = llm_content.get('description', '')
        title = llm_content.get('title', '')
        context_text = f"{title} {description}".lower()
        
        # –°–ø–∏—Å–æ–∫ –æ–±—â–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ
        generic_terms = {
            '–≤–µ—Ä—Ö–Ω—è—è –æ–¥–µ–∂–¥–∞': ['—Ä—É–±–∞—à–∫–∞', '–∫—É—Ä—Ç–∫–∞', '—Å–≤–∏—Ç–µ—Ä', '–∫–æ—Ñ—Ç–∞', '–ø–∏–¥–∂–∞–∫', '–∂–∏–ª–µ—Ç', '—Ö—É–¥–∏', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞'],
            '–æ–¥–µ–∂–¥–∞': ['—Ä—É–±–∞—à–∫–∞', '–±—Ä—é–∫–∏', '–∫—É—Ä—Ç–∫–∞', '—Å–≤–∏—Ç–µ—Ä', '—Ñ—É—Ç–±–æ–ª–∫–∞', '–ø–ª–∞—Ç—å–µ', '—é–±–∫–∞'],
            '–∏–∑–¥–µ–ª–∏–µ': ['—Ä—É–±–∞—à–∫–∞', '–±—Ä—é–∫–∏', '–∫—É—Ä—Ç–∫–∞', '—Å–≤–∏—Ç–µ—Ä', '—Ñ—É—Ç–±–æ–ª–∫–∞', '–ø–ª–∞—Ç—å–µ', '—é–±–∫–∞'],
            '–Ω–∏–∂–Ω–µ–µ –±–µ–ª—å–µ': ['—Ç—Ä—É—Å—ã', '–º–∞–π–∫–∞', '–±—é—Å—Ç–≥–∞–ª—å—Ç–µ—Ä'],
            '–æ–±—É–≤—å': ['–∫—Ä–æ—Å—Å–æ–≤–∫–∏', '–±–æ—Ç–∏–Ω–∫–∏', '—Ç—É—Ñ–ª–∏', '—Å–∞–ø–æ–≥–∏', '–±–æ—Å–æ–Ω–æ–∂–∫–∏'],
        }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ price_lines
        price_labels = [item['label'].lower() for item in price_lines]
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—â–µ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ –≤ —Ü–µ–Ω–∞—Ö –∏—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
        fixed_lines = []
        for item in price_lines:
            label = item['label']
            label_lower = label.lower()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±—â–∏–º —Ç–µ—Ä–º–∏–Ω–æ–º
            replacement = None
            for generic, concrete_options in generic_terms.items():
                if generic in label_lower:
                    # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∏–ø—ã —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
                    for concrete in concrete_options:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ:
                        # 1. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
                        # 2. –≠—Ç–æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –µ—â—ë –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –¥—Ä—É–≥–∏—Ö —Ü–µ–Ω–∞—Ö
                        if concrete in context_text and concrete not in price_labels:
                            replacement = label_lower.replace(generic, concrete)
                            break
                    if replacement:
                        break
            
            if replacement:
                fixed_lines.append({"label": replacement, "price": item['price']})
            else:
                fixed_lines.append(item)
        
        return fixed_lines
    
    async def _prepare_price_entries(self, product_data: dict, product_context: dict | str | None) -> list[dict]:
        """
        –ì–æ—Ç–æ–≤–∏—Ç —Å–ø–∏—Å–æ–∫ —Ü–µ–Ω –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º SKU –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ—Å—Ç–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ü–µ–Ω–æ–≤—ã—Ö –≥—Ä—É–ø–ø.
        
        Args:
            product_data: –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ
            product_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≤–∞—Ä–∞ (dict —Å title –∏ description) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ title (str) –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        """
        entries = self._get_unique_sku_price_items(product_data)
        if len(entries) <= 1:
            return []
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ dict
        if isinstance(product_context, str):
            product_context = {'title': product_context, 'description': ''}
        elif not product_context:
            product_context = {'title': '', 'description': ''}

        if self._translation_supports_structured_tasks():
            if settings.DEBUG_MODE:
                print("[Scraper] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LLM-–≤–µ—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ü–µ–Ω")
            structured = await self._process_prices_with_llm(entries, product_context)
            if structured:
                return structured

        if settings.DEBUG_MODE:
            print("[Scraper] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback-–≤–µ—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ü–µ–Ω (–±–µ–∑ LLM)")
        return await self._prepare_price_entries_fallback(entries)

    async def _process_prices_with_llm(self, entries: list[dict], product_context: dict) -> list[dict]:
        """
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç translation LLM –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ —Å–∂–∞—Ç–∏—è —Å–ø–∏—Å–∫–∞ —Ü–µ–Ω.
        
        Args:
            entries: –°–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å —Ü–µ–Ω–∞–º–∏
            product_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≤–∞—Ä–∞ (title, description)
        """
        try:
            translated = await self._translate_price_entries_with_llm(entries, product_context)
            if not translated:
                return []
            summarized = await self._summarize_price_entries_with_llm(product_context, translated)
            return summarized
        except Exception as e:
            if settings.DEBUG_MODE:
                print(f"[Scraper] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ü–µ–Ω —á–µ—Ä–µ–∑ LLM: {e}")
            return []

    async def _translate_price_entries_with_llm(self, entries: list[dict], product_context: dict) -> list[dict]:
        payload = json.dumps(entries, ensure_ascii=False, indent=2)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        title = product_context.get('title', '')
        description = product_context.get('description', '')
        
        system_prompt = (
            "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–æ–≤–∞—Ä–Ω—ã–º –∫–∞—Ç–∞–ª–æ–≥–∞–º –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤. "
            "–ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–æ–≤–∞—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ, "
            "–∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ö–û–ù–ö–†–ï–¢–ù–´–• —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–∞."
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        context_lines = []
        if title:
            context_lines.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {title}")
        if description:
            context_lines.append(f"–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {description}")
        
        context_hint = "\n".join(context_lines) + "\n\n" if context_lines else ""
        
        user_prompt = (
            f"{context_hint}"
            "–ù–∏–∂–µ –ø–µ—Ä–µ–¥–∞–Ω JSON-–º–∞—Å—Å–∏–≤ –ø–æ–∑–∏—Ü–∏–π —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ —Ü–µ–Ω–∞–º–∏ –≤ —é–∞–Ω—è—Ö.\n"
            "–ü–µ—Ä–µ–≤–µ–¥–∏ –∫–∞–∂–¥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –ß–ï–°–¢–ù–û –∏ –ü–û–õ–ù–û–°–¢–¨–Æ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n"
            "–í–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ –≤–∏–¥–∞: [{\"label\": \"–ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ\", \"price\": —á–∏—Å–ª–æ}].\n\n"
            "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ß–ï–°–¢–ù–´–ô –ü–û–õ–ù–´–ô –ü–ï–†–ï–í–û–î:\n\n"
            "1. –°–û–•–†–ê–ù–Ø–ô —Å—Ç—Ä—É–∫—Ç—É—Ä—É: [–¢–ò–ü –¢–û–í–ê–†–ê], [–æ–ø–∏—Å–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞/–ø—Ä–∏–Ω—Ç–∞]\n"
            "   - 'XS, ÈïøË¢ñÂ•óË£Ö, MARBLE MUSHROOM PRINT' ‚Üí '–º–∞–π–∫–∞, –ø—Ä–∏–Ω—Ç –º—Ä–∞–º–æ—Ä–Ω—ã–π –≥—Ä–∏–±–Ω–æ–π'\n"
            "   - 'M, Áü≠Ë£§, BLACK' ‚Üí '—à–æ—Ä—Ç—ã, —á—ë—Ä–Ω—ã–µ'\n"
            "   - 'L, ÈïøË£§, RED PRINT' ‚Üí '–±—Ä—é–∫–∏, –ø—Ä–∏–Ω—Ç –∫—Ä–∞—Å–Ω—ã–π'\n\n"
            "2. –û–ü–†–ï–î–ï–õ–ò –¢–ò–ü —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∫–∏—Ç–∞–π—Å–∫–∏—Ö —Å–ª–æ–≤:\n"
            "   - 'ÈïøË¢ñ' / 'ÈïøË¢ñÂ•óË£Ö' ‚Üí '–º–∞–π–∫–∞' –∏–ª–∏ '—Ñ—É—Ç–±–æ–ª–∫–∞' (–¥–ª–∏–Ω–Ω—ã–π —Ä—É–∫–∞–≤)\n"
            "   - 'Áü≠Ë£§' ‚Üí '—à–æ—Ä—Ç—ã' (–∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã)\n"
            "   - 'ÈïøË£§' ‚Üí '–±—Ä—é–∫–∏' (–¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã)\n"
            "   - 'Ë°¨Ë°´' ‚Üí '—Ä—É–±–∞—à–∫–∞'\n"
            "   - 'Ë£§Â≠ê' ‚Üí '–±—Ä—é–∫–∏'\n\n"
            "3. –ü–ï–†–ï–í–û–î–ò –ø—Ä–∏–Ω—Ç—ã/—Ü–≤–µ—Ç–∞, –Ω–æ —Å—Ç–∞–≤—å –ò–• –ü–û–°–õ–ï —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞:\n"
            "   - 'MARBLE MUSHROOM PRINT, ÁîúÂ•∂Ê≤πÁ∫¢ËòëËèá, ÈïøË¢ñ' ‚Üí '–º–∞–π–∫–∞, –ø—Ä–∏–Ω—Ç –º—Ä–∞–º–æ—Ä–Ω—ã–π –≥—Ä–∏–±–Ω–æ–π'\n"
            "   - 'CARAMEL GINGERBREAD PRINT, ÁÑ¶Á≥ñÂ∞è‰∫∫ÂÑøÂßúÈ•ºÂπ≤, Áü≠Ë£§' ‚Üí '—à–æ—Ä—Ç—ã, –ø—Ä–∏–Ω—Ç –∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π –∏–º–±–∏—Ä–Ω—ã–π –ø—Ä—è–Ω–∏–∫'\n"
            "   - 'BLACK, ÈªëËâ≤, ÈïøË£§' ‚Üí '–±—Ä—é–∫–∏, —á—ë—Ä–Ω—ã–µ'\n\n"
            "4. –ò–°–ü–û–õ–¨–ó–£–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –£–¢–û–ß–ù–ï–ù–ò–Ø —Ç–∏–ø–∞:\n"
            "   - –ï—Å–ª–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏: '–ö–æ–º–ø–ª–µ–∫—Ç: –º–∞–π–∫–∞, —à–æ—Ä—Ç—ã, –±—Ä—é–∫–∏'\n"
            "   - –ò –≤ –≤–∞—Ä–∏–∞–Ω—Ç–µ: 'ÈïøË¢ñ' ‚Üí –ø–µ—Ä–µ–≤–æ–¥–∏ –∫–∞–∫ '–º–∞–π–∫–∞' (–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n"
            "   - –ò –≤ –≤–∞—Ä–∏–∞–Ω—Ç–µ: 'Áü≠Ë£§' ‚Üí –ø–µ—Ä–µ–≤–æ–¥–∏ –∫–∞–∫ '—à–æ—Ä—Ç—ã' (–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n\n"
            "5. –ù–ï –£–î–ê–õ–Ø–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:\n"
            "   - –ü–µ—Ä–µ–≤–æ–¥–∏ –í–°–Å: —Ä–∞–∑–º–µ—Ä—ã, –ø—Ä–∏–Ω—Ç—ã, —Ü–≤–µ—Ç–∞ (—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç –ø–æ–∑–∂–µ)\n"
            "   - –§–æ—Ä–º–∞—Ç: '–¢–ò–ü –¢–û–í–ê–†–ê, –∞—Ç—Ä–∏–±—É—Ç—ã'\n"
            "   - –ü—Ä–∏–º–µ—Ä: '–º–∞–π–∫–∞, –ø—Ä–∏–Ω—Ç –º—Ä–∞–º–æ—Ä–Ω—ã–π –≥—Ä–∏–±–Ω–æ–π' (–ù–ï –ø—Ä–æ—Å—Ç–æ '–º–∞–π–∫–∞')\n\n"
            "–ü–†–ò–ú–ï–†–´:\n\n"
            "–í—Ö–æ–¥: {\"name\": \"XS, ÈïøË¢ñÂ•óË£Ö, MARBLE MUSHROOM PRINT ÁîúÂ•∂Ê≤πÁ∫¢ËòëËèá\", \"price\": 158}\n"
            "–í—ã—Ö–æ–¥: {\"label\": \"–º–∞–π–∫–∞, –ø—Ä–∏–Ω—Ç –º—Ä–∞–º–æ—Ä–Ω—ã–π –≥—Ä–∏–±–Ω–æ–π\", \"price\": 158}\n\n"
            "–í—Ö–æ–¥: {\"name\": \"M, Áü≠Ë£§, WASHED ONYX SKI PRINT Ê∞¥Ê¥óÈªë\", \"price\": 118}\n"
            "–í—ã—Ö–æ–¥: {\"label\": \"—à–æ—Ä—Ç—ã, –ø—Ä–∏–Ω—Ç —Å—Ç–∏—Ä–∞–Ω—ã–π —á—ë—Ä–Ω—ã–π –ª—ã–∂–Ω—ã–π\", \"price\": 118}\n\n"
            "–í—Ö–æ–¥: {\"name\": \"L, ÈïøË£§, CARAMEL GINGERBREAD\", \"price\": 188}\n"
            "–í—ã—Ö–æ–¥: {\"label\": \"–±—Ä—é–∫–∏, –ø—Ä–∏–Ω—Ç –∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π –∏–º–±–∏—Ä–Ω—ã–π –ø—Ä—è–Ω–∏–∫\", \"price\": 188}\n\n"
            "–¶–µ–Ω—ã –ù–ï –∏–∑–º–µ–Ω—è–π. –ü–µ—Ä–µ–≤–æ–¥–∏ –ß–ï–°–¢–ù–û –∏ –ü–û–õ–ù–û–°–¢–¨–Æ.\n\n"
            f"–ò—Å—Ö–æ–¥–Ω—ã–π JSON:\n{payload}"
        )
        token_limit = max(2000, len(entries) * 80)
        last_error = None

        for attempt in range(2):
            try:
                response_text = await self._call_translation_json(
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    token_limit=token_limit,
                    temperature=0.0,
                )
                data = self._parse_json_response(response_text)
                normalized = []
                for item in data if isinstance(data, list) else []:
                    label = str(item.get('label') or item.get('name') or "").strip()
                    price = item.get('price')
                    try:
                        price_value = float(price)
                    except (TypeError, ValueError):
                        continue
                    if label:
                        normalized.append({"label": label, "price": price_value})
                if normalized:
                    return normalized
                last_error = ValueError("LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Ü–µ–Ω.")
            except json.JSONDecodeError as exc:
                last_error = exc
                token_limit = int(token_limit * 1.5) + 500
                continue

        if last_error:
            raise last_error
        return []

    async def _summarize_price_entries_with_llm(self, product_context: dict, items: list[dict]) -> list[dict]:
        if not items:
            return []
        
        payload = json.dumps(items, ensure_ascii=False, indent=2)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        title = product_context.get('title', '')
        description = product_context.get('description', '')
        
        system_prompt = (
            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–æ–≤–∞—Ä–Ω—ã–º –∫–∞—Ç–∞–ª–æ–≥–∞–º –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤. –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–µ –∏ —Ç–æ—á–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ü–µ–Ω, "
            "–∫–∞–∫ –Ω–∞ Wildberries –∏–ª–∏ Ozon. –û–±–æ–±—â–∞–π –≤–∞—Ä–∏–∞—Ü–∏–∏, –µ—Å–ª–∏ —Ä–∞–∑–ª–∏—á–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã (—Ä–∞–∑–º–µ—Ä, —Ü–≤–µ—Ç, –ø—Ä–∏–Ω—Ç). "
            "–ï—Å–ª–∏ —Ä–∞–∑–ª–∏—á–∏—è –≤–ª–∏—è—é—Ç –Ω–∞ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–ª–∏ –∫–æ–º–ø–ª–µ–∫—Ç–Ω–æ—Å—Ç—å - –æ—Å—Ç–∞–≤–ª—è–π –æ—Ç–¥–µ–ª—å–Ω–æ."
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_lines = []
        if title:
            context_lines.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: {title}")
        if description:
            context_lines.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")
        
        context_hint = "\n".join(context_lines) + "\n\n" if context_lines else ""
        
        user_prompt = (
            f"{context_hint}"
            "–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥—ë–Ω JSON-–º–∞—Å—Å–∏–≤ –ø–æ–∑–∏—Ü–∏–π —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –∏ —Ü–µ–Ω–∞–º–∏:\n"
            f"{payload}\n\n"
            "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ì–†–£–ü–ü–ò–†–û–í–ö–ê –ü–û –¢–ò–ü–£ –¢–û–í–ê–†–ê, –ù–ï –ü–û –ü–†–ò–ù–¢–£!\n\n"
            "–ü–†–ê–í–ò–õ–ê –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò (—Å—Ç–∏–ª—å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞ Wildberries/Ozon):\n\n"
            "1. –û–ü–†–ï–î–ï–õ–ò –¢–ò–ü –¢–û–í–ê–†–ê –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è (–º–∞–π–∫–∞, —Ñ—É—Ç–±–æ–ª–∫–∞, —à–æ—Ä—Ç—ã, –±—Ä—é–∫–∏, —à—Ç–∞–Ω—ã, —Ä—É–±–∞—à–∫–∞ –∏ —Ç.–¥.)\n"
            "   - '–¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞, –ø—Ä–∏–Ω—Ç X' ‚Üí –¢–ò–ü = '—Ñ—É—Ç–±–æ–ª–∫–∞' –∏–ª–∏ '–º–∞–π–∫–∞'\n"
            "   - '–∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã, —Ü–≤–µ—Ç Y' ‚Üí –¢–ò–ü = '—à–æ—Ä—Ç—ã'\n"
            "   - '–¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã, –ø—Ä–∏–Ω—Ç Z' ‚Üí –¢–ò–ü = '–±—Ä—é–∫–∏'\n"
            "   - '—Ä—É–±–∞—à–∫–∞ —Å –ø–∞–π–µ—Ç–∫–∞–º–∏' ‚Üí –¢–ò–ü = '—Ä—É–±–∞—à–∫–∞'\n\n"
            "2. –ì–†–£–ü–ü–ò–†–£–ô –ø–æ –¢–ò–ü–£ —Ç–æ–≤–∞—Ä–∞ + –¶–ï–ù–ï (–∏–≥–Ω–æ—Ä–∏—Ä—É–π –ø—Ä–∏–Ω—Ç—ã, —Ü–≤–µ—Ç–∞, —Ä–∞–∑–º–µ—Ä—ã!):\n"
            "   - –í—Å–µ '—Ñ—É—Ç–±–æ–ª–∫–∞ [–ª—é–±–æ–π –ø—Ä–∏–Ω—Ç]' —Å —Ü–µ–Ω–æ–π 158 ¬• ‚Üí '–º–∞–π–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ'\n"
            "   - –í—Å–µ '–∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã [–ª—é–±–æ–π —Ü–≤–µ—Ç]' —Å —Ü–µ–Ω–æ–π 118 ¬• ‚Üí '—à–æ—Ä—Ç—ã –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ'\n"
            "   - –ù–ï –≥—Ä—É–ø–ø–∏—Ä—É–π –ø–æ –ø—Ä–∏–Ω—Ç–∞–º! '–º–∞—Ä–º–æ—Ä–Ω—ã–π –ø—Ä–∏–Ω—Ç' - –ù–ï —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞!\n\n"
            "3. –ù–û–†–ú–ê–õ–ò–ó–£–ô –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–∞:\n"
            "   - '–¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞' / '–¥–ª–∏–Ω–Ω—ã–π —Ä—É–∫–∞–≤' ‚Üí '–º–∞–π–∫–∞'\n"
            "   - '–∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã' / '–∫–æ—Ä–æ—Ç–∫–∏–µ –±—Ä—é–∫–∏' ‚Üí '—à–æ—Ä—Ç—ã'\n"
            "   - '–¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã' / '–¥–ª–∏–Ω–Ω—ã–µ –±—Ä—é–∫–∏' ‚Üí '–±—Ä—é–∫–∏'\n"
            "   - '—Ñ—É—Ç–±–æ–ª–∫–∞' / '—Ç–æ–ø' ‚Üí '—Ñ—É—Ç–±–æ–ª–∫–∞'\n\n"
            "4. –§–û–†–ú–ê–¢ –æ–ø–∏—Å–∞–Ω–∏—è (2-4 —Å–ª–æ–≤–∞):\n"
            "   - –ï—Å–ª–∏ —Ä–∞–∑–Ω—ã–µ –ø—Ä–∏–Ω—Ç—ã: '–º–∞–π–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ'\n"
            "   - –ï—Å–ª–∏ –æ–¥–∏–Ω —Ü–≤–µ—Ç: '—à–æ—Ä—Ç—ã —á—ë—Ä–Ω—ã–µ'\n"
            "   - –ï—Å–ª–∏ –æ–¥–∏–Ω —Ç–∏–ø –±–µ–∑ –≤–∞—Ä–∏–∞—Ü–∏–π: '–±—Ä—é–∫–∏'\n\n"
            "‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è –ü–†–ò–ú–ï–†–´ –° –ü–†–ò–ù–¢–ê–ú–ò (–∫–∞–∫ –≤ –≤–∞—à–µ–º —Å–ª—É—á–∞–µ) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n\n"
            "–ü—Ä–∏–º–µ—Ä 1 - –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∫–æ–º–ø–ª–µ–∫—Ç–∞ —Å –ø—Ä–∏–Ω—Ç–∞–º–∏ SKIMS:\n"
            "–í—Ö–æ–¥: [\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç MARBLE MUSHROOM, —Ü–≤–µ—Ç –Ω–µ–∂–Ω–æ-—Ä–æ–∑–æ–≤—ã–π —Å –∫—Ä–∞—Å–Ω—ã–º –≥—Ä–∏–±–∫–æ–º, –¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞\", \"price\": 158},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç CARAMEL GINGERBREAD, —Ü–≤–µ—Ç –∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π –∏–º–±–∏—Ä–Ω—ã–π –ø—Ä—è–Ω–∏–∫, –¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞\", \"price\": 158},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç WASHED ONYX SKI, —Ü–≤–µ—Ç –≤—ã–º—ã—Ç—ã–π —á—ë—Ä–Ω—ã–π, –¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞\", \"price\": 158},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç MARBLE MUSHROOM, —Ü–≤–µ—Ç –Ω–µ–∂–Ω–æ-—Ä–æ–∑–æ–≤—ã–π —Å –∫—Ä–∞—Å–Ω—ã–º –≥—Ä–∏–±–∫–æ–º, –∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã\", \"price\": 118},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç WASHED ONYX SKI, —Ü–≤–µ—Ç –≤—ã–º—ã—Ç—ã–π —á—ë—Ä–Ω—ã–π, –∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã\", \"price\": 118},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç CARAMEL GINGERBREAD, —Ü–≤–µ—Ç –∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π, –∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã\", \"price\": 118},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç MARBLE MUSHROOM, —Ü–≤–µ—Ç –Ω–µ–∂–Ω–æ-—Ä–æ–∑–æ–≤—ã–π, –¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã\", \"price\": 188},\n"
            "  {\"label\": \"–ü—Ä–∏–Ω—Ç WASHED ONYX SKI, –¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã\", \"price\": 188}\n"
            "]\n"
            "–í—ã—Ö–æ–¥: [\n"
            "  {\"label\": \"–º–∞–π–∫–∞ —Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ\", \"price\": 158},\n"
            "  {\"label\": \"—à–æ—Ä—Ç—ã —Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ\", \"price\": 118},\n"
            "  {\"label\": \"–±—Ä—é–∫–∏ —Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ\", \"price\": 188}\n"
            "]\n"
            "–õ–æ–≥–∏–∫–∞: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¢–ò–ü–£ —Ç–æ–≤–∞—Ä–∞ (–º–∞–π–∫–∞, —à–æ—Ä—Ç—ã, –±—Ä—é–∫–∏), –ù–ï –ø–æ –ø—Ä–∏–Ω—Ç—É!\n\n"
            "–ü—Ä–∏–º–µ—Ä 2 - –ù–ï–ü–†–ê–í–ò–õ–¨–ù–ê–Ø –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ (—Ç–∞–∫ –¥–µ–ª–∞—Ç—å –ù–ï–õ–¨–ó–Ø):\n"
            "–í—ã—Ö–æ–¥ –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ô: [\n"
            "  {\"label\": \"–º–∞—Ä–º–æ—Ä–Ω—ã–π –≥—Ä–∏–±–Ω–æ–π –ø—Ä–∏–Ω—Ç\", \"price\": 158},  ‚Üê –û–®–ò–ë–ö–ê! –ü—Ä–∏–Ω—Ç - –Ω–µ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞!\n"
            "  {\"label\": \"–∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π –∏–º–±–∏—Ä–Ω—ã–π –ø–µ—á–µ–Ω—å–µ\", \"price\": 158},  ‚Üê –û–®–ò–ë–ö–ê!\n"
            "  {\"label\": \"–ø—Ä–∏–Ω—Ç —Å–∫–∏ –æ–Ω–∏–∫—Å–∞ –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ\", \"price\": 118}  ‚Üê –û–®–ò–ë–ö–ê!\n"
            "]\n\n"
            "–ü—Ä–∏–º–µ—Ä 3 - –†—É–±–∞—à–∫–∞ –∏ –±—Ä—é–∫–∏:\n"
            "–í—Ö–æ–¥: [\n"
            "  {\"label\": \"XS –±—Ä—é–∫–∏ —á—ë—Ä–Ω—ã–µ\", \"price\": 128},\n"
            "  {\"label\": \"S –±—Ä—é–∫–∏ —á—ë—Ä–Ω—ã–µ\", \"price\": 128},\n"
            "  {\"label\": \"XS —Ä—É–±–∞—à–∫–∞ —Å –ø–∞–π–µ—Ç–∫–∞–º–∏ –±–µ–ª–∞—è\", \"price\": 148},\n"
            "  {\"label\": \"S —Ä—É–±–∞—à–∫–∞ —Å –ø–∞–π–µ—Ç–∫–∞–º–∏ –±–µ–ª–∞—è\", \"price\": 148}\n"
            "]\n"
            "–í—ã—Ö–æ–¥: [\n"
            "  {\"label\": \"–±—Ä—é–∫–∏\", \"price\": 128},\n"
            "  {\"label\": \"—Ä—É–±–∞—à–∫–∞ —Å –ø–∞–π–µ—Ç–∫–∞–º–∏\", \"price\": 148}\n"
            "]\n\n"
            "–ê–õ–ì–û–†–ò–¢–ú:\n"
            "–®–∞–≥ 1: –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏–∑–≤–ª–µ–∫–∏ –¢–ò–ü —Ç–æ–≤–∞—Ä–∞ (–º–∞–π–∫–∞/—à–æ—Ä—Ç—ã/–±—Ä—é–∫–∏/—Ä—É–±–∞—à–∫–∞)\n"
            "–®–∞–≥ 2: –°–≥—Ä—É–ø–ø–∏—Ä—É–π –ø–æ (–¢–ò–ü —Ç–æ–≤–∞—Ä–∞, –¶–ï–ù–ê)\n"
            "–®–∞–≥ 3: –î–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ë–ï–ó –ø—Ä–∏–Ω—Ç–æ–≤/—Ü–≤–µ—Ç–æ–≤/—Ä–∞–∑–º–µ—Ä–æ–≤\n"
            "–®–∞–≥ 4: –ï—Å–ª–∏ –≤ –≥—Ä—É–ø–ø–µ >1 –≤–∞—Ä–∏–∞–Ω—Ç —Å —Ä–∞–∑–Ω—ã–º–∏ –ø—Ä–∏–Ω—Ç–∞–º–∏/—Ü–≤–µ—Ç–∞–º–∏ ‚Üí –¥–æ–±–∞–≤—å '–≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ'\n\n"
            "–í–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ [{\"label\": \"–æ–ø–∏—Å–∞–Ω–∏–µ\", \"price\": —á–∏—Å–ª–æ}]. "
            "–û–ø–∏—Å–∞–Ω–∏–µ: 2-4 —Å–ª–æ–≤–∞, –¢–ò–ü —Ç–æ–≤–∞—Ä–∞ + (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) '—Å –ø—Ä–∏–Ω—Ç–æ–º –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ'. "
            "–ì—Ä—É–ø–ø–∏—Ä—É–π –¢–û–õ–¨–ö–û –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞ –∏ —Ü–µ–Ω–µ!"
        )
        token_limit = max(2000, len(items) * 40)
        last_error = None

        for attempt in range(2):
            try:
                response_text = await self._call_translation_json(
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    token_limit=token_limit,
                    temperature=0.0,
                )
                data = self._parse_json_response(response_text)
                result = []
                seen = set()
                for item in data if isinstance(data, list) else []:
                    label = str(item.get('label') or "").strip()
                    price = item.get('price')
                    try:
                        price_value = float(price)
                    except (TypeError, ValueError):
                        continue
                    if not label:
                        continue
                    key = (label, price_value)
                    if key in seen:
                        continue
                    seen.add(key)
                    result.append({"label": label, "price": price_value})

                if result:
                    price_groups: OrderedDict[float, list[str]] = OrderedDict()
                    for entry in sorted(result, key=lambda e: e['price']):
                        price_groups.setdefault(entry['price'], []).append(entry['label'])

                    merged: list[dict] = []
                    for price_value, labels in price_groups.items():
                        if not labels:
                            continue
                        merged_label = self._merge_price_labels(labels)
                        if isinstance(merged_label, list):
                            for lbl in merged_label:
                                cleaned = (lbl or "").strip()
                                if cleaned:
                                    merged.append({"label": cleaned, "price": price_value})
                        else:
                            cleaned = (merged_label or "").strip()
                            if cleaned:
                                merged.append({"label": cleaned, "price": price_value})

                    return merged
                last_error = ValueError("LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ü–µ–Ω.")
            except json.JSONDecodeError as exc:
                last_error = exc
                token_limit = int(token_limit * 1.5) + 500
                continue

        if last_error:
            raise last_error
        return []

    async def _prepare_price_entries_fallback(self, entries: list[dict]) -> list[dict]:
        grouped: OrderedDict[float, list[str]] = OrderedDict()
        for entry in entries:
            grouped.setdefault(entry['price'], []).append(entry['name'])

        if len(grouped) <= 1:
            return []

        all_names = [name for names in grouped.values() for name in names]
        translated_names = await self._translate_variant_names(all_names)

        idx = 0
        summarized_lines = []
        for price_value, names in grouped.items():
            translated_group = []
            for _ in names:
                translated = translated_names[idx] if idx < len(translated_names) else _
                idx += 1
                translated_group.append(translated.strip() or _)
            summaries = self._summarize_price_group(translated_group)
            for label in summaries:
                cleaned_label = (label or "").strip()
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º–∞—Ä–∫–µ—Ä—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
                if cleaned_label and "__INVALID__" not in cleaned_label.upper():
                    summarized_lines.append({"label": cleaned_label, "price": price_value})

        # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: –µ—Å–ª–∏ –¥–ª—è –æ–¥–Ω–æ–π —Ü–µ–Ω—ã –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤,
        # –∏ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –º—É—Å–æ—Ä - —É–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä–Ω—ã–π
        price_groups: dict[float, list[dict]] = {}
        for item in summarized_lines:
            price = item['price']
            if price not in price_groups:
                price_groups[price] = []
            price_groups[price].append(item)
        
        filtered_lines = []
        for price, items in price_groups.items():
            if len(items) > 1:
                # –ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ü–µ–Ω–æ–π
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ (–æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞)
                valid_items = []
                suspicious_keywords = ['—Ç–æ–≤–∞—Ä', '–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è', '–¥–æ—Å—Ç–∞–≤–∫–∞', '–±–µ–∑']
                
                for item in items:
                    label_lower = item['label'].lower()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –º—É—Å–æ—Ä–æ–º
                    is_suspicious = (
                        len(item['label']) < 5 or  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        sum(1 for kw in suspicious_keywords if kw in label_lower) >= 2  # –ú–Ω–æ–≥–æ –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤
                    )
                    if not is_suspicious:
                        valid_items.append(item)
                
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–∏—Å—å –≤–∞–ª–∏–¥–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö, –∏–Ω–∞—á–µ - –≤—Å–µ
                filtered_lines.extend(valid_items if valid_items else items)
            else:
                # –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç —Å —ç—Ç–æ–π —Ü–µ–Ω–æ–π - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                filtered_lines.extend(items)

        unique = []
        seen = set()
        for item in filtered_lines:
            key = (item['label'], item['price'])
            if key in seen:
                continue
            seen.add(key)
            unique.append(item)
        return unique

    def _get_unique_sku_price_items(self, product_data: dict) -> list[dict]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ (–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ + —Ü–µ–Ω–∞).
        """
        items = []
        seen = set()
        for sku in product_data.get('skus', []) or []:
            price_str = sku.get('sale_price') or sku.get('origin_price')
            try:
                price_value = float(str(price_str).replace(',', '.'))
            except (TypeError, ValueError):
                continue

            name = self._normalize_sku_prop_name(sku.get('props_names') or '')
            if not name:
                continue

            key = (name.lower(), price_value)
            if key in seen:
                continue
            seen.add(key)
            items.append({'name': name, 'price': price_value})
        return items

    def _normalize_sku_prop_name(self, props_names: str) -> str:
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç props_names –∫ —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ–º—É –≤–∏–¥—É –±–µ–∑ –∫–ª—é—á–µ–π.
        """
        if not props_names:
            return ""

        parts = []
        for part in props_names.split(';'):
            part = part.strip()
            if not part:
                continue
            if ':' in part:
                _, value = part.split(':', 1)
            else:
                value = part
            value = value.strip()
            if value:
                parts.append(value)
        return ", ".join(parts) if parts else props_names.strip()

    async def _translate_variant_names(self, names: list[str]) -> list[str]:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫.
        """
        if not names:
            return names

        if self.translation_supports_structured:
            payload = [{"id": idx, "label": name} for idx, name in enumerate(names)]
            token_limit = max(800, len(names) * 40)
            user_prompt = (
                "–ù–∏–∂–µ –ø–µ—Ä–µ–¥–∞–Ω JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏ id –∏ label. "
                "–ü–µ—Ä–µ–≤–µ–¥–∏ –ø–æ–ª–µ label –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Ç–æ—Ç –∂–µ id. "
                "–í–µ—Ä–Ω–∏ –º–∞—Å—Å–∏–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{\"id\": 0, \"label\": \"–ø–µ—Ä–µ–≤–æ–¥\"}]. "
                "–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ –Ω–µ –º–µ–Ω—è–π –ø–æ—Ä—è–¥–æ–∫.\n\n"
                f"{json.dumps(payload, ensure_ascii=False, indent=2)}"
            )
            for attempt in range(2):
                try:
                    response_text = await self._call_translation_json(
                        system_prompt="–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π JSON.",
                        user_prompt=user_prompt,
                        token_limit=token_limit,
                        temperature=0.0,
                    )
                    data = self._parse_json_response(response_text)
                    translated_map: dict[int, str] = {}
                    if isinstance(data, list):
                        for item in data:
                            try:
                                idx = int(item.get("id"))
                            except Exception:
                                continue
                            label = (item.get("label") or item.get("text") or "").strip()
                            if label:
                                translated_map[idx] = label
                    if len(translated_map) == len(names):
                        return [translated_map[idx] for idx in range(len(names))]
                except json.JSONDecodeError as exc:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] –û—à–∏–±–∫–∞ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {exc}")
                    token_limit = int(token_limit * 1.5) + 200
                    continue
                except Exception as exc:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] –û—à–∏–±–∫–∞ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {exc}")
                    break


        translator = getattr(self.translation_client, "translate_text", None)
        if not callable(translator):
            return names

        batch_text = "\n".join(names)
        translated_block = None
        try:
            translated_block = await translator(batch_text, target_language="ru")
        except Exception as exc:
            if settings.DEBUG_MODE:
                print(f"[Scraper] –û—à–∏–±–∫–∞ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤: {exc}")

        if translated_block:
            splitted = [line.strip() for line in translated_block.split("\n")]
            if len(splitted) == len(names):
                return [segment or original for segment, original in zip(splitted, names)]

        results = []
        for name in names:
            try:
                translated = await translator(name, target_language="ru")
            except Exception:
                translated = None
            results.append((translated or name).strip() or name)
        return results

    def _extract_product_type(self, name: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è, —É–±–∏—Ä–∞—è —Ä–∞–∑–º–µ—Ä—ã, —Ü–≤–µ—Ç–∞, –ø—Ä–∏–Ω—Ç—ã –∏ –¥—Ä—É–≥–∏–µ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞.
        
        –§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¢–ò–ü–ê –æ–¥–µ–∂–¥—ã (–º–∞–π–∫–∞, —à–æ—Ä—Ç—ã, –±—Ä—é–∫–∏), –∏–≥–Ω–æ—Ä–∏—Ä—É—è –ø—Ä–∏–Ω—Ç—ã –∏ —Ü–≤–µ—Ç–∞.
        """
        if not name:
            return ""
        
        name_lower = name.lower()
        
        # –°–ø–∏—Å–æ–∫ "–º—É—Å–æ—Ä–Ω—ã—Ö" —Ñ—Ä–∞–∑, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —è–≤–ª—è—é—Ç—Å—è —Ç–∏–ø–∞–º–∏ —Ç–æ–≤–∞—Ä–∞
        garbage_phrases = [
            '—Ç–æ–≤–∞—Ä –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è',
            '—Ç–æ–≤–∞—Ä –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –±–µ–∑',
            '–±–µ–∑ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–≥–æ –ª–µ–π–±–ª–∞',
            '–±–µ–∑ –±—Ä–µ–Ω–¥–æ–≤–æ–π –º–∞—Ä–∫–∏—Ä–æ–≤–∫–∏',
            '–±–µ–∑ –±—Ä–µ–Ω–¥–∞',
            '–æ—Ç–ø—Ä–∞–≤–∫–∞ –±–µ–∑',
            '–¥–æ—Å—Ç–∞–≤–∫–∞',
            '–≤ –Ω–∞–ª–∏—á–∏–∏',
            '–ø–æ–¥ –∑–∞–∫–∞–∑',
            '–ø—Ä–µ–¥–∑–∞–∫–∞–∑',
            '–Ω–æ–≤–∏–Ω–∫–∞',
            '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞',
            '—Å–∫–∏–¥–∫–∞',
            '–∞–∫—Ü–∏—è',
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º—É—Å–æ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        for garbage in garbage_phrases:
            if garbage in name_lower:
                # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º—É—Å–æ—Ä–Ω—É—é —Ñ—Ä–∞–∑—É –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —è–≤–Ω–æ–≥–æ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Ä–∫–µ—Ä
                # –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∏–∂–µ, –µ—Å—Ç—å –ª–∏ —è–≤–Ω—ã–π —Ç–∏–ø
                has_product_type = False
                for markers in [
                    ['–º–∞–π–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∞', '—Ç–æ–ø', '–±–ª—É–∑–∞'],
                    ['—à–æ—Ä—Ç—ã', '–±—Ä—é–∫–∏', '—à—Ç–∞–Ω—ã'],
                    ['—Ä—É–±–∞—à–∫–∞', '—Å–æ—Ä–æ—á–∫–∞'],
                    ['–∫—É—Ä—Ç–∫–∞', '–ø–∏–¥–∂–∞–∫'],
                    ['—Å–≤–∏—Ç–µ—Ä', '–¥–∂–µ–º–ø–µ—Ä', '–∫–æ—Ñ—Ç–∞', '—Ö—É–¥–∏'],
                    ['–ø–ª–∞—Ç—å–µ', '—é–±–∫–∞'],
                ]:
                    if any(marker in name_lower for marker in markers):
                        has_product_type = True
                        break
                
                if not has_product_type:
                    # –ú—É—Å–æ—Ä–Ω–∞—è —Ñ—Ä–∞–∑–∞ –±–µ–∑ —è–≤–Ω–æ–≥–æ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞ - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
                    return "__INVALID__"
        
        # –°–ª–æ–≤–∞—Ä—å –º–∞—Ä–∫–µ—Ä–æ–≤ —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–∞ (–≤–∞–∂–Ω–µ–µ –≤—Å–µ–≥–æ!)
        type_markers = {
            '–º–∞–π–∫–∞': ['–º–∞–π–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∞', '–¥–ª–∏–Ω–Ω–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞', '–¥–ª–∏–Ω–Ω—ã–π —Ä—É–∫–∞–≤', '—Ç–æ–ø', '–±–ª—É–∑–∞'],
            '—à–æ—Ä—Ç—ã': ['—à–æ—Ä—Ç—ã', '–∫–æ—Ä–æ—Ç–∫–∏–µ —à—Ç–∞–Ω—ã', '–∫–æ—Ä–æ—Ç–∫–∏–µ –±—Ä—é–∫–∏'],
            '–±—Ä—é–∫–∏': ['–±—Ä—é–∫–∏', '–¥–ª–∏–Ω–Ω—ã–µ —à—Ç–∞–Ω—ã', '–¥–ª–∏–Ω–Ω—ã–µ –±—Ä—é–∫–∏', '—à—Ç–∞–Ω—ã'],
            '—Ä—É–±–∞—à–∫–∞': ['—Ä—É–±–∞—à–∫–∞', '—Å–æ—Ä–æ—á–∫–∞'],
            '–∫—É—Ä—Ç–∫–∞': ['–∫—É—Ä—Ç–∫–∞', '–ø–∏–¥–∂–∞–∫', '–∂–∞–∫–µ—Ç'],
            '—Å–≤–∏—Ç–µ—Ä': ['—Å–≤–∏—Ç–µ—Ä', '–¥–∂–µ–º–ø–µ—Ä', '–∫–æ—Ñ—Ç–∞', '—Ö—É–¥–∏', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞'],
            '–ø–ª–∞—Ç—å–µ': ['–ø–ª–∞—Ç—å–µ'],
            '—é–±–∫–∞': ['—é–±–∫–∞'],
        }
        
        # –ò—â–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        for product_type, markers in type_markers.items():
            for marker in markers:
                if marker in name_lower:
                    return product_type
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —è–≤–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ä–∞ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback-–ª–æ–≥–∏–∫—É
        # –ù–æ –ø–æ–º–Ω–∏–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω –≤ –∫–æ–Ω—Ü–µ
        # –°–ø–∏—Å–æ–∫ —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
        size_patterns = [
            r'\b(xs|s|m|l|xl|xxl|xxxl)\b',  # –ë—É–∫–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
            r'\b(\d{1,3})\b',  # –ß–∏—Å–ª–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (35, 36, 37, ...)
            r'\b(one\s*size|free\s*size|—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π)\b',  # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        ]
        
        # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
        cleaned = name_lower
        for pattern in size_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø—Ä–∏–Ω—Ç–∞–º–∏ –∏ —Ü–≤–µ—Ç–∞–º–∏
        print_keywords = ['–ø—Ä–∏–Ω—Ç', 'print', '—Ä–∏—Å—É–Ω–æ–∫', '—É–∑–æ—Ä', 'pattern']
        for keyword in print_keywords:
            # –£–±–∏—Ä–∞–µ–º —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–ø—Ä–∏–Ω—Ç –º—Ä–∞–º–æ—Ä–Ω—ã–π", "print marble"
            cleaned = re.sub(rf'\b{keyword}\b[^,\.]*', '', cleaned, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º –∑–∞–ø—è—Ç—ã–µ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        cleaned = re.sub(r'^[,\s]+', '', cleaned)
        cleaned = re.sub(r'[,\s]+$', '', cleaned)
        cleaned = re.sub(r'\s*,\s*', ' ', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # –£–±–∏—Ä–∞–µ–º —Ü–≤–µ—Ç–∞
        cleaned = self._remove_color_words(cleaned)
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]+", cleaned.lower())
        filtered = [
            token for token in tokens
            if token not in self.GENERIC_STOPWORDS
            and len(token) > 2
        ]
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
        if filtered:
            candidate = " ".join(filtered[:2])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Ü–≤–µ—Ç–æ–º/–ø—Ä–∏–Ω—Ç–æ–º –±–µ–∑ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞
            # –°–ø–∏—Å–æ–∫ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—ã—á–Ω–æ –æ–ø–∏—Å—ã–≤–∞—é—Ç —Ü–≤–µ—Ç/–ø—Ä–∏–Ω—Ç, –Ω–æ –Ω–µ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
            color_adjectives = [
                '–∫–∞—Ä–∞–º–µ–ª—å–Ω—ã–π', '–º—Ä–∞–º–æ—Ä–Ω—ã–π', '–∏–º–±–∏—Ä–Ω—ã–π', '—Å—Ç–∏—Ä–∞–Ω—ã–π', '–≤—ã–º—ã—Ç—ã–π',
                '—á—ë—Ä–Ω—ã–π', '–±–µ–ª—ã–π', '–∫—Ä–∞—Å–Ω—ã–π', '—Å–∏–Ω–∏–π', '–∑–µ–ª—ë–Ω—ã–π', '–∂—ë–ª—Ç—ã–π',
                '–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π', '—Å–µ—Ä—ã–π', '—Ä–æ–∑–æ–≤—ã–π', '—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π', '–æ—Ä–∞–Ω–∂–µ–≤—ã–π',
                '–Ω–µ–∂–Ω—ã–π', '—è—Ä–∫–∏–π', '—Ç—ë–º–Ω—ã–π', '—Å–≤–µ—Ç–ª—ã–π', '–ø–∞—Å—Ç–µ–ª—å–Ω—ã–π',
                '–ø–µ—á–µ–Ω—å–µ', '–ø—Ä—è–Ω–∏–∫', '–≥—Ä–∏–±–Ω–æ–π', '–ª—ã–∂–Ω—ã–π', '–æ–Ω–∏–∫—Å'
            ]
            
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ —Ü–≤–µ—Ç–æ–≤—ã—Ö –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö - —ç—Ç–æ –Ω–µ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
            candidate_words = candidate.lower().split()
            all_colors = all(word in color_adjectives for word in candidate_words)
            
            if all_colors:
                # –≠—Ç–æ —Ü–≤–µ—Ç/–ø—Ä–∏–Ω—Ç, –∞ –Ω–µ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ - –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
                return "__INVALID__"
            
            return candidate
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        # –ï—Å–ª–∏ –æ–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ü–≤–µ—Ç–∞/–ø—Ä–∏–Ω—Ç—ã –±–µ–∑ —Ç–∏–ø–∞ - –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π
        final_candidate = cleaned.strip() or name.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ü–≤–µ—Ç/–ø—Ä–∏–Ω—Ç
        if final_candidate and len(final_candidate) > 0:
            # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ - –Ω–µ–≤–∞–ª–∏–¥–Ω–æ
            words = final_candidate.lower().split()
            if len(words) <= 2 and all(
                any(color_word in word for color_word in ['–∫–∞—Ä–∞–º–µ–ª—å', '–º—Ä–∞–º–æ—Ä', '–∏–º–±–∏—Ä', '–ø—Ä–∏–Ω—Ç', 'print'])
                for word in words
            ):
                return "__INVALID__"
        
        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ç–∏–ø–æ–º —Ç–æ–≤–∞—Ä–∞
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–∞
        known_types = {
            '–º–∞–π–∫–∞', '—Ñ—É—Ç–±–æ–ª–∫–∞', '—Ç–æ–ø', '–±–ª—É–∑–∞',
            '—à–æ—Ä—Ç—ã', '–±—Ä—é–∫–∏', '—à—Ç–∞–Ω—ã',
            '—Ä—É–±–∞—à–∫–∞', '—Å–æ—Ä–æ—á–∫–∞',
            '–∫—É—Ä—Ç–∫–∞', '–ø–∏–¥–∂–∞–∫', '–∂–∞–∫–µ—Ç',
            '—Å–≤–∏—Ç–µ—Ä', '–¥–∂–µ–º–ø–µ—Ä', '–∫–æ—Ñ—Ç–∞', '—Ö—É–¥–∏', '—Ç–æ–ª—Å—Ç–æ–≤–∫–∞',
            '–ø–ª–∞—Ç—å–µ', '—é–±–∫–∞',
            '–Ω–æ—Å–∫–∏', '–∫–æ–ª–≥–æ—Ç–∫–∏', '–≥–æ–ª—å—Ñ—ã',
            '—Ç—Ä—É—Å—ã', '–±–µ–ª—å–µ',
            '–ø–∏–∂–∞–º–∞', '—Ö–∞–ª–∞—Ç',
            '–∫–æ–º–±–∏–Ω–µ–∑–æ–Ω',
        }
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ —Ç–∏–ø–∞ - —ç—Ç–æ –Ω–µ —Ç–æ–≤–∞—Ä
        if final_candidate:
            final_lower = final_candidate.lower()
            has_known_type = any(known_type in final_lower for known_type in known_types)
            if not has_known_type:
                # –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–∞ - —ç—Ç–æ –º—É—Å–æ—Ä (—Ü–≤–µ—Ç/–ø—Ä–∏–Ω—Ç)
                return "__INVALID__"
        
        return final_candidate
    
    def _summarize_price_group(self, names: list[str]) -> list[str]:
        """
        –°–æ–∫—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –ø–æ–∑–∏—Ü–∏–π, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–æ–≤ –≤ –ø–æ—Å—Ç–µ.
        
        –õ–æ–≥–∏–∫–∞:
        1. –£–¥–∞–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑ –≤—Å–µ—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
        2. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ —Ç–∏–ø—É —Ç–æ–≤–∞—Ä–∞
        3. –ï—Å–ª–∏ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ (—Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä—ã/—Ü–≤–µ—Ç–∞ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è) ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
        4. –ï—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ ‚Üí –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç —Ç–∏–ø—ã, –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ç–∏–ø–æ–≤ ‚Üí "–≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ"
        """
        if not names:
            return []
        
        # –®–∞–≥ 1: –£–¥–∞–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏ —Ü–≤–µ—Ç–∞ –∏–∑ –≤—Å–µ—Ö –Ω–∞–∑–≤–∞–Ω–∏–π, –ø–æ–ª—É—á–∞–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
        type_to_originals: dict[str, list[str]] = {}
        for name in names:
            name = name.strip()
            if not name:
                continue
            
            product_type = self._extract_product_type(name)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Ç–∏–ø—ã
            if product_type == "__INVALID__":
                continue
            
            if not product_type:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                product_type = name
            
            if product_type not in type_to_originals:
                type_to_originals[product_type] = []
            type_to_originals[product_type].append(name)
        
        if not type_to_originals:
            return []
        
        # –®–∞–≥ 2: –ï—Å–ª–∏ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
        if len(type_to_originals) == 1:
            product_type = list(type_to_originals.keys())[0]
            originals = type_to_originals[product_type]
            
            # –ï—Å–ª–∏ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã (–∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç—ã)
            unique_originals = list(dict.fromkeys(originals))
            if len(unique_originals) > 1:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –ª–∏ –æ–Ω–∏ —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏
                # –ï—Å–ª–∏ –¥–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
                return [product_type]
            else:
                # –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                return unique_originals
        
        # –®–∞–≥ 3: –ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π
        result = []
        for product_type, originals in type_to_originals.items():
            unique_originals = list(dict.fromkeys(originals))
            
            if len(unique_originals) == 1:
                # –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
                result.append(product_type)
            else:
                # –ù–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ (—Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã/—Ü–≤–µ—Ç–∞)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –ª–∏ –æ–Ω–∏ —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏
                # –ï—Å–ª–∏ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏ - —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
                # –ï—Å–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ü–≤–µ—Ç–∞–º–∏/–¥—Ä—É–≥–∏–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ - —É–∫–∞–∑—ã–≤–∞–µ–º "–≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ"
                
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ –≤—Å–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
                all_contain_type = all(product_type in orig.lower() for orig in unique_originals)
                if all_contain_type:
                    # –í—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏
                    result.append(product_type)
                else:
                    # –í–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ —Ä–∞–∑–º–µ—Ä–∞–º–∏
                    result.append(f"{product_type} –≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ")
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        unique_result = []
        seen = set()
        for item in result:
            item_lower = item.lower()
            if item_lower not in seen:
                seen.add(item_lower)
                unique_result.append(item)
        
        return unique_result

    def _extract_keywords(self, names: list[str]) -> list[str]:
        counter = Counter()
        for name in names:
            tokens = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]+", name.lower())
            filtered = [
                token for token in tokens
                if token not in self.COLOR_KEYWORDS
                and token not in self.GENERIC_STOPWORDS
                and len(token) > 2
            ]
            counter.update(filtered)

        keywords = []
        for token, _ in counter.most_common():
            if token not in keywords:
                keywords.append(token)
            if len(keywords) >= 5:
                break
        return keywords

    def _extract_shared_descriptor(self, names: list[str]) -> str:
        normalized = [name.lower() for name in names]
        if normalized and all(self._contains_keyword(name, self.BATTERY_KEYWORDS) for name in normalized):
            return "–Ω–∞ –±–∞—Ç–∞—Ä–µ–π–∫–∞—Ö"
        if normalized and all(self._contains_keyword(name, self.CHARGE_KEYWORDS) for name in normalized):
            return "–ø–µ—Ä–µ–∑–∞—Ä—è–∂–∞–µ–º—ã–µ"
        return ""

    @staticmethod
    def _contains_keyword(text: str, keywords: tuple[str, ...]) -> bool:
        text = text.lower()
        return any(keyword in text for keyword in keywords)

    def _is_apparel_product(self, translated_title: str | None, product_data: dict) -> bool:
        text_parts = [
            translated_title or "",
            product_data.get('title') or "",
            product_data.get('product_props') or "",
            " ".join(product_data.get('category_path') or []),
        ]
        text = " ".join(text_parts).lower()
        apparel_markers = (
            "–ø–ª–∞—Ç—å", "—é–±–∫", "–¥–∂–∏–Ω—Å", "–±—Ä—é–∫", "—Ä—É–±–∞—à", "—Ñ—É—Ç–±–æ–ª–∫", "—Ç–æ–ª—Å—Ç–æ–≤",
            "—Ö—É–¥–∏", "–∫–æ—Å—Ç—é–º", "–∂–∏–ª–µ—Ç", "–∫—É—Ä—Ç–∫", "–ø–∞–ª—å—Ç", "—à–æ—Ä—Ç", "–ª–µ–≥–≥–∏–Ω—Å",
            "–æ–±—É–≤", "–±–æ—Ç–∏–Ω", "–∫—Ä–æ—Å—Å–æ–≤", "—Ç—É—Ñ–ª", "–∫–µ–¥—ã", "–Ω–æ—Å–∫", "–±–µ–ª—å",
            "–∫–æ–ª–≥–æ—Ç", "–ø–∏–∂–∞–º", "–∫–æ–º–±–∏–Ω–µ–∑", "—Å–∫–∏–Ω–Ω–∏", "sneaker", "coat", "hoodie",
            "Èù¥", "Ë°£", "Ë£ô", "Ë£§", "Ë°´"
        )
        return any(marker in text for marker in apparel_markers)

    @staticmethod
    def _common_prefix(lhs: str, rhs: str) -> str:
        limit = min(len(lhs), len(rhs))
        idx = 0
        while idx < limit and lhs[idx] == rhs[idx]:
            idx += 1
        return lhs[:idx]

    def _remove_color_words(self, text: str) -> str:
        if not text:
            return ""
        cleaned = self.COLOR_REGEX.sub("", text)
        cleaned = re.sub(r"\s{2,}", " ", cleaned)
        cleaned = cleaned.replace(" ,", ",").replace(" /", "/")
        return cleaned.strip(" ,./-")

    def _merge_price_labels(self, labels: list[str]) -> str | list[str]:
        if not labels:
            return []
        if len(labels) == 1:
            return labels[0]

        prefix = labels[0]
        for lbl in labels[1:]:
            prefix = self._common_prefix(prefix, lbl)
            if not prefix:
                break

        prefix = prefix.rstrip(" -‚Äî:,()/").strip()
        if prefix and len(prefix) >= 12:
            suffixes = []
            for lbl in labels:
                suffix = lbl[len(prefix):].lstrip(" -‚Äî:,()").strip()
                suffix = self._remove_color_words(suffix)
                if not suffix:
                    suffix = "–≤–∞—Ä–∏–∞–Ω—Ç"
                suffixes.append(suffix)
            unique_suffixes = []
            seen = set()
            for suf in suffixes:
                normalized = suf.lower()
                if normalized not in seen:
                    seen.add(normalized)
                    unique_suffixes.append(suf)
            if unique_suffixes:
                joined = ", ".join(unique_suffixes[:6])
                if len(unique_suffixes) > 6:
                    joined += ", –∏ –¥—Ä."
                return f"{prefix} (–≤ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ: {joined})"
            return prefix

        # –ù–µ—Ç –æ–±—â–µ–≥–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        return labels

    def _translation_supports_structured_tasks(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–µ—Å–∫–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        —Å–ª–æ–∂–Ω—ã–µ JSON-–∑–∞–¥–∞—á–∏ (–ø–µ—Ä–µ–≤–æ–¥ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ü–µ–Ω —á–µ—Ä–µ–∑ LLM).

        –î–ª—è ProxyAPI –º—ã —Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º —ç—Ç–æ—Ç —Ä–µ–∂–∏–º, —á—Ç–æ–±—ã:
        - –∏–∑–±–µ–∂–∞—Ç—å —Ü–µ–ø–æ—á–µ–∫ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—è–º–∏ gpt-5.x;
        - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ProxyAPI —Ç–æ–ª—å–∫–æ –∫–∞–∫ –±—ã—Å—Ç—Ä—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ chat.completions.
        """
        try:
            from src.api.proxyapi_client import ProxyAPIClient  # –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤

            if isinstance(self.translation_client, ProxyAPIClient):
                return False
        except Exception:
            # –µ—Å–ª–∏ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–∏—á–∏–Ω–µ –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è, –Ω–µ –ª–æ–º–∞–µ–º—Å—è
            pass

        return hasattr(self.translation_client, "generate_json_response")

    def _parse_json_response(self, text: str):
        cleaned = text.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        if cleaned.startswith("```"):
            cleaned = cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        cleaned = cleaned.strip()
        return json.loads(cleaned)

    async def _call_translation_json(
        self,
        system_prompt: str,
        user_prompt: str,
        token_limit: int = 1500,
        temperature: float = 0.0,
    ) -> str:
        generator = getattr(self.translation_client, "generate_json_response", None)
        if not callable(generator):
            raise RuntimeError("–ê–∫—Ç–∏–≤–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–µ—Å–∫–∏–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç JSON-–æ—Ç–≤–µ—Ç—ã.")

        kwargs = {
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
        }

        try:
            sig = inspect.signature(generator)
            if "max_output_tokens" in sig.parameters:
                kwargs["max_output_tokens"] = token_limit
            elif "max_tokens" in sig.parameters:
                kwargs["max_tokens"] = token_limit
            if "temperature" in sig.parameters:
                kwargs["temperature"] = temperature
        except (TypeError, ValueError):
            kwargs["max_tokens"] = token_limit

        return await generator(**kwargs)

    async def _translate_text_generic(self, text: str, target_language: str = "ru") -> str:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π translation_client.
        """
        if not text:
            return text

        translator = getattr(self.translation_client, "translate_text", None)
        if callable(translator):
            try:
                translated = await translator(text, target_language=target_language)
                if translated:
                    return translated
            except Exception as e:
                if settings.DEBUG_MODE:
                    print(f"[Scraper] –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return text
    
    def _format_size_range(self, sizes_str: str) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω—ã–π —Ä—è–¥. –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω.
        
        Args:
            sizes_str: –°—Ç—Ä–æ–∫–∞ —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "S, M, L" –∏–ª–∏ "35, 36, 37, 38")
        
        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤
        """
        if not sizes_str or not sizes_str.strip():
            return sizes_str
            
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –æ–¥–µ–∂–¥—ã –≤ –ø–æ—Ä—è–¥–∫–µ
        standard_sizes = ['XXS', 'XS', 'S', 'M', 'L', 'XL', 'XXL', 'XXXL']
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—á–∏—â–∞–µ–º
        sizes_raw = [s.strip() for s in sizes_str.replace(',', ' ').split() if s.strip()]
        
        # –ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã (–æ–±—É–≤—å)
        try:
            numeric_sizes = [float(s) for s in sizes_raw]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
            if len(numeric_sizes) > 2:
                sorted_sizes = sorted(numeric_sizes)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å —à–∞–≥–æ–º 1
                is_sequential = all(
                    sorted_sizes[i+1] - sorted_sizes[i] == 1.0 
                    for i in range(len(sorted_sizes)-1)
                )
                if is_sequential:
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ –µ—Å–ª–∏ –æ–Ω–∏ —Ü–µ–ª—ã–µ
                    first = int(sorted_sizes[0]) if sorted_sizes[0].is_integer() else sorted_sizes[0]
                    last = int(sorted_sizes[-1]) if sorted_sizes[-1].is_integer() else sorted_sizes[-1]
                    return f"{first}-{last}"
            # –ï—Å–ª–∏ –Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
            return ", ".join(str(int(s) if s.is_integer() else s) for s in numeric_sizes)
        except (ValueError, AttributeError):
            # –ù–µ —á–∏—Å–ª–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –±—É–∫–≤–µ–Ω–Ω—ã–µ
            pass
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–∫–≤–µ–Ω–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ (–æ–¥–µ–∂–¥–∞)
        sizes = [s.upper() for s in sizes_raw]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ —Ä–∞–∑–º–µ—Ä—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ
        if all(s in standard_sizes for s in sizes):
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
            indices = [standard_sizes.index(s) for s in sizes]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–±–µ–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤)
            if len(indices) > 1 and indices == list(range(min(indices), max(indices) + 1)):
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
                return f"{sizes[0]}-{sizes[-1]}"
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
        return ", ".join(sizes_raw)

    def _ensure_lowercase_bullet(self, text: str) -> str:
        """
        –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –ø–µ—Ä–≤—ã–π –∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª –≤ –ø—É–Ω–∫—Ç–µ —Å–ø–∏—Å–∫–∞ ‚Äî —Å—Ç—Ä–æ—á–Ω—ã–π.
        """
        if not text:
            return text
        chars = list(text)
        for idx, ch in enumerate(chars):
            if ch.isalpha():
                chars[idx] = ch.lower()
                return "".join(chars)
        return text

    def _render_price_section(
        self,
        price_lines: list[dict],
        fallback_price: str,
        currency: str,
        exchange_rate: float | None
    ) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å–µ–∫—Ü–∏—é —Å —Ü–µ–Ω–∞–º–∏.
        """
        if price_lines:
            unique_prices = {entry['price'] for entry in price_lines}
            if len(unique_prices) == 1:
                price_value = unique_prices.pop()
                amount = self._format_price_amount(price_value, currency, exchange_rate)
                return f"<i>üí∞ <b>–¶–µ–Ω–∞:</b> {amount}</i>"

            lines = ["<i>üí∞ <b>–¶–µ–Ω—ã:</b></i>"]
            for entry in price_lines:
                amount = self._format_price_amount(entry['price'], currency, exchange_rate)
                label = self._ensure_lowercase_bullet(entry['label'])
                lines.append(f"<i>  ‚Ä¢ {label} - {amount}</i>")
            return "\n".join(lines)

        amount = self._format_price_value_string(fallback_price, currency, exchange_rate)
        if not amount:
            return ""
        return f"<i>üí∞ <b>–¶–µ–Ω–∞:</b> {amount}</i>"

    def _format_price_amount(self, price_value: float, currency: str, exchange_rate: float | None) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å —É—á—ë—Ç–æ–º –≤–∞–ª—é—Ç—ã.
        """
        try:
            numeric = float(price_value)
        except (TypeError, ValueError):
            numeric = None

        if currency == "rub" and exchange_rate and numeric is not None:
            rub_price = numeric * float(exchange_rate)
            rub_price_rounded = round(rub_price / 10) * 10
            return f"{int(rub_price_rounded)} ‚ÇΩ + –¥–æ—Å—Ç–∞–≤–∫–∞"

        if numeric is not None:
            return f"{self._format_number(numeric)} ¬• + –¥–æ—Å—Ç–∞–≤–∫–∞"

        return "N/A"

    @staticmethod
    def _format_number(value: float) -> str:
        """
        –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –Ω—É–ª–∏ —É —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.
        """
        if float(value).is_integer():
            return f"{int(value)}"
        return f"{value:.2f}".rstrip('0').rstrip('.')

    def _format_price_value_string(
        self,
        price_value: str,
        currency: str,
        exchange_rate: float | None
    ) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ü–µ–Ω—É, –µ—Å–ª–∏ –æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ.
        """
        if not price_value:
            return ""
        try:
            numeric = float(str(price_value).replace(',', '.'))
            return self._format_price_amount(numeric, currency, exchange_rate)
        except (ValueError, TypeError):
            suffix = "‚ÇΩ" if currency == "rub" and exchange_rate else "¬•"
            return f"{price_value} {suffix} + –¥–æ—Å—Ç–∞–≤–∫–∞"
    
    def _build_post_text(
        self, 
        llm_content: dict, 
        product_data: dict, 
        signature: str = None,
        currency: str = "cny",
        exchange_rate: float = None,
        price_lines: list | None = None
    ) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö LLM –∏ –¥–∞–Ω–Ω—ã—Ö API.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç HTML —Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è Telegram.

        Args:
            llm_content (dict): –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç YandexGPT
            product_data (dict): –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –æ—Ç TMAPI
            signature (str, optional): –ü–æ–¥–ø–∏—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ—Å—Ç–∞
            currency (str): –í–∞–ª—é—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (cny –∏–ª–∏ rub)
            exchange_rate (float, optional): –ö—É—Ä—Å –æ–±–º–µ–Ω–∞ CNY –≤ RUB

        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –≤ HTML
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–ø–∏—Å—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        user_signature = signature or settings.DEFAULT_SIGNATURE
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ LLM –æ—Ç–≤–µ—Ç–∞
        title = llm_content.get('title', '–¢–æ–≤–∞—Ä')
        description = llm_content.get('description', '')
        main_characteristics = llm_content.get('main_characteristics', {})
        additional_info = llm_content.get('additional_info', {})
        hashtags = llm_content.get('hashtags', [])
        emoji = llm_content.get('emoji', '')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É (–ø–µ—Ä–≤–∏—á–Ω–æ –∏–∑ skus), –¥–∞–ª–µ–µ ‚Äî –Ω–∞–¥—ë–∂–Ω—ã–µ —Ñ–æ–ª–±—ç–∫–∏
        price = self._get_max_price_from_skus(product_data)
        if not price:
            price = str((product_data.get('price_info') or {}).get('price') or '').strip()
        if not price:
            price = str(product_data.get('price') or '').strip()
        if not price:
            price = str((product_data.get('pdd_minimal') or {}).get('price') or '').strip()
        
        # –°–∞–Ω–∏—Ç–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è/–æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö —Ñ–∞—Å–æ–Ω–æ–≤ –∏ –≥–æ–¥–æ–≤
        try:
            src_text = ((product_data.get('details') or '') + ' ' + (product_data.get('title') or '')).lower()
            def _neutralize_underwear(text: str) -> str:
                t = text
                # –ï—Å–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç "–±–æ–∫—Å", –Ω–æ –µ—Å—Ç—å "—Ç—Ä—É—Å—ã" ‚Äî –∑–∞–º–µ–Ω—è–µ–º "–±–æ–∫—Å—ë—Ä—ã" –Ω–∞ "—Ç—Ä—É—Å—ã"
                if '—Ç—Ä—É—Å—ã' in src_text and '–±–æ–∫—Å' not in src_text:
                    t = t.replace('—Ç—Ä—É—Å—ã-–±–æ–∫—Å—ë—Ä—ã', '—Ç—Ä—É—Å—ã')
                    t = t.replace('–±–æ–∫—Å—ë—Ä—ã', '—Ç—Ä—É—Å—ã')
                return t
            def _remove_years(text: str) -> str:
                import re
                return re.sub(r"\b(20\d{2})\b", "", text).replace('  ', ' ').strip()
            title = _remove_years(_neutralize_underwear(title))
            description = _remove_years(_neutralize_underwear(description))
        except Exception:
            pass

        if settings.DEBUG_MODE:
            price_info = product_data.get('price_info', {})
            print(f"[Scraper] –ò—Ç–æ–≥–æ–≤–∞—è —Ü–µ–Ω–∞: {price}")
            print(f"[Scraper] –¶–µ–Ω–∞ –∏–∑ price_info: {price_info.get('price', 'N/A')}")
            if 'origin_price' in price_info:
                print(f"[Scraper] Origin price: {price_info.get('origin_price')}")
        
        product_url = product_data.get('product_url', '')
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç
        post_parts = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å —ç–º–æ–¥–∑–∏ (–∂–∏—Ä–Ω—ã–º –∫—É—Ä—Å–∏–≤–æ–º)
        title_line = f"{emoji} " if emoji else ""
        title_line += f"<i><b>{title}</b></i>"
        post_parts.append(title_line)
        post_parts.append("")
        
        # –û–ø–∏—Å–∞–Ω–∏–µ –≤ –≤–∏–¥–µ —Ü–∏—Ç–∞—Ç—ã (–∫—É—Ä—Å–∏–≤–æ–º)
        if description:
            post_parts.append(f"<blockquote><i>{description}</i></blockquote>")
            post_parts.append("")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        if main_characteristics:
            # –°–ø–∏—Å–æ–∫ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö/–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            invalid_values = [
                '–¥—Ä—É–≥–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã', '–ø—Ä–æ—á–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 
                '—Å–º–µ—à–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã', 'other materials', 'unknown', 
                'mixed', 'various', '–ø—Ä–æ—á–∏–µ', '–¥—Ä—É–≥–∏–µ', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ',
                '–Ω–µ —É–∫–∞–∑–∞–Ω', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞', '–Ω–µ —É–∫–∞–∑–∞–Ω—ã',
                '–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö', 'no information',
                'not specified', '–Ω/–¥', 'n/a', ''
            ]
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            # –ü–æ—Ä—è–¥–æ–∫: –°–æ—Å—Ç–∞–≤/–ú–∞—Ç–µ—Ä–∏–∞–ª ‚Üí –¶–≤–µ—Ç–∞ ‚Üí –†–∞–∑–º–µ—Ä—ã/–û–±—ä—ë–º ‚Üí –û—Å—Ç–∞–ª—å–Ω–æ–µ
            ordered_keys = []
            
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Å—Ç–∞–≤/–º–∞—Ç–µ—Ä–∏–∞–ª (–µ—Å–ª–∏ –µ—Å—Ç—å –∏ –æ–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π)
            for key in main_characteristics.keys():
                if '–º–∞—Ç–µ—Ä–∏–∞–ª' in key.lower() or '—Å–æ—Å—Ç–∞–≤' in key.lower():
                    value = main_characteristics[key]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ –∏ –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö
                    if value and isinstance(value, str) and value.strip() and value.lower().strip() not in invalid_values:
                        ordered_keys.append(key)
            
            # –ó–∞—Ç–µ–º —Ü–≤–µ—Ç–∞
            for key in main_characteristics.keys():
                if '—Ü–≤–µ—Ç' in key.lower() or 'color' in key.lower():
                    value = main_characteristics[key]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ü–≤–µ—Ç–∞ –Ω–µ –ø—É—Å—Ç—ã–µ
                    if value and (isinstance(value, list) and len(value) > 0 or isinstance(value, str) and value.strip()):
                        ordered_keys.append(key)
            
            # –ó–∞—Ç–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏ –æ–±—ä—ë–º—ã
            for key in main_characteristics.keys():
                if '—Ä–∞–∑–º–µ—Ä' in key.lower() or 'size' in key.lower() or '–æ–±—ä—ë–º' in key.lower() or '–æ–±—ä–µ–º' in key.lower():
                    value = main_characteristics[key]
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ –∏ –Ω–µ "–Ω–µ —É–∫–∞–∑–∞–Ω"
                    if value and isinstance(value, str) and value.strip() and value.lower().strip() not in invalid_values:
                        ordered_keys.append(key)
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–µ)
            for key in main_characteristics.keys():
                if key not in ordered_keys:
                    value = main_characteristics[key]
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
                    if value and (isinstance(value, list) and len(value) > 0 or isinstance(value, str) and value.strip()):
                        ordered_keys.append(key)
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            for key in ordered_keys:
                value = main_characteristics[key]
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                if isinstance(value, str) and value.lower().strip() in invalid_values:
                    if settings.DEBUG_MODE:
                        print(f"[Scraper] –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ '{key}': '{value}'")
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                if not value:
                    continue
                if isinstance(value, str) and not value.strip():
                    continue
                if isinstance(value, list) and len(value) == 0:
                    continue
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –µ—Å–ª–∏ —ç—Ç–æ —Ä–∞–∑–º–µ—Ä—ã
                if '—Ä–∞–∑–º–µ—Ä' in key.lower() and isinstance(value, str):
                    value = self._format_size_range(value)
                
                if isinstance(value, list):
                    # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ - —Å–ø–∏—Å–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ü–≤–µ—Ç–∞)
                    post_parts.append(f"<i><b>{key}:</b></i>")
                    for item in value:
                        # –ü–æ—Å–ª–µ –º–∞—Ä–∫–µ—Ä–∞ —Å–ª–æ–≤–æ –¥–æ–ª–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å–æ —Å—Ç—Ä–æ—á–Ω–æ–π –±—É–∫–≤—ã
                        formatted_item = str(item).strip()
                        if formatted_item:
                            formatted_item = self._ensure_lowercase_bullet(formatted_item)
                        post_parts.append(f"<i>  ‚Ä¢ {formatted_item}</i>")
                    post_parts.append("")
                else:
                    # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ - —Å—Ç—Ä–æ–∫–∞
                    post_parts.append(f"<i><b>{key}:</b> {value}</i>")
        
        # –î–ª—è Pinduoduo (–∏ —Å—Ö–æ–∂–∏—Ö): –∏–∑–≤–ª–µ—á—ë–º –≤–∞–∂–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
        try:
            platform = product_data.get('_platform')
            if platform == 'pinduoduo':
                import re
                desc_text = (product_data.get('details') or '')
                if desc_text:
                    extracted: dict = {}
                    m = re.search(r"(?i)–ú–∞—Ç–µ—Ä–∏–∞–ª[:Ôºö]\s*([^\n]+)", desc_text)
                    if m:
                        extracted.setdefault('–ú–∞—Ç–µ—Ä–∏–∞–ª', m.group(1).strip())
                    m = re.search(r"(?i)–ü–æ–¥–∫–ª–∞–¥–∫–∞[:Ôºö]\s*([^\n]+)", desc_text)
                    if m:
                        extracted.setdefault('–ü–æ–¥–∫–ª–∞–¥–∫–∞', m.group(1).strip())
                    m = re.search(r"(?i)(–¢–∏–ø –∑–∞—Å—Ç—ë–∂–∫–∏|–ó–∞—Å—Ç—ë–∂–∫–∞)[:Ôºö]\s*([^\n]+)", desc_text)
                    if m:
                        extracted.setdefault('–¢–∏–ø –∑–∞—Å—Ç—ë–∂–∫–∏', m.group(2).strip())
                    # –°–ª–∏–≤–∞–µ–º –≤ main_characteristics, –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ
                    for k, v in extracted.items():
                        if not v:
                            continue
                        if k not in main_characteristics or not str(main_characteristics.get(k) or '').strip():
                            main_characteristics[k] = v
        except Exception:
            pass

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å)
        if additional_info:
            for key, value in additional_info.items():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                if value and str(value).strip():
                    post_parts.append(f"<i><b>{key}:</b> {value}</i>")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –¥–æ–ø. –¥–∞–Ω–Ω—ã–µ
            if any(v and str(v).strip() for v in additional_info.values()):
                post_parts.append("")
        
        # –ï—Å–ª–∏ –±—ã–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø –ø–µ—Ä–µ–¥ —Ü–µ–Ω–æ–π
        if main_characteristics or additional_info:
            if not post_parts[-1] == "":
                post_parts.append("")
        
        # –¶–µ–Ω–∞ —Å —É—á—ë—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –≤–∞–ª—é—Ç—ã
        currency_lower = (currency or "cny").lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ exchange_rate –Ω–µ None –∏ –Ω–µ 0
        has_exchange_rate = exchange_rate is not None and float(exchange_rate) > 0
        
        price_block = self._render_price_section(
            price_lines=price_lines or [],
            fallback_price=price,
            currency=currency_lower,
            exchange_rate=exchange_rate if has_exchange_rate else None
        )
        if price_block:
            post_parts.append(price_block)
            post_parts.append("")
        
        # –ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é (–∫—É—Ä—Å–∏–≤–æ–º) —Å –ø–æ–¥–ø–∏—Å—å—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        contact = user_signature.strip() if user_signature.strip() else settings.DEFAULT_SIGNATURE
        post_parts.append(f"<i>üìù –î–ª—è –∑–∞–∫–∞–∑–∞ –ø–∏—à–∏—Ç–µ {contact} –∏–ª–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö üõçÔ∏è</i>")
        post_parts.append("")
        
        # –•—ç—à—Ç–µ–≥–∏ (–∫—É—Ä—Å–∏–≤–æ–º)
        # –û—á–∏—â–∞–µ–º —Ö—ç—à—Ç–µ–≥–∏ –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ (–ø—Ä–æ–≥—Ä–∞–º–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ LLM –¥–æ–±–∞–≤–∏–ª –ø—Ä–æ–±–µ–ª—ã)
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –∏–∑ —Ö—ç—à—Ç–µ–≥–æ–≤, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        if hashtags:
            cleaned_hashtags = [tag.strip().replace(" ", "") for tag in hashtags if tag and tag.strip()]
            hashtag_text = " ".join([f"#{tag}" for tag in cleaned_hashtags if tag])
            if hashtag_text:  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ö—ç—à—Ç–µ–≥
                post_parts.append(f"<i>{hashtag_text}</i>")
                post_parts.append("")
        
        # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
        if product_url:
            post_parts.append(f'<a href="{product_url}">–°—Å—ã–ª–∫–∞</a>')
        
        return "\n".join(post_parts)
